<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE section PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="Containerized_Logging">
  <title>Logging em contêiner</title>

  <sect1 id="HPCC_Systems_ContainerLogging" role="nobrk">
    <title>Histórico de Logging</title>

    <para>Os logs de componentes do Bare-metal HPCC Systems são gravados em
    arquivos persistentes no sistema de arquivos local. Em contraste, os logs
    HPCC em contêiner são efêmeros e sua localização nem sempre é bem
    definida. Os componentes do HPCC Systems fornecem logs informativos no
    nível do aplicativo para fins de depuração de problemas, ações de
    auditoria e monitoramento do progresso.</para>

    <para>Seguindo as metodologias em contêiner mais amplamente aceitas, as
    informações de log de componentes do HPCC Systems são roteadas para os
    fluxos de saída padrão em vez de arquivos locais. Em implantações em
    contêiner, não há logs de componentes gravados em arquivos como nas
    edições anteriores.</para>

    <para>Esses logs são gravados no fluxo de erro padrão (stderr). No nível
    do nó, o conteúdo do erro padrão e dos fluxos de saída são redirecionados
    para um local de destino por um mecanismo de contêiner. Em um ambiente
    Kubernetes, o mecanismo de contêiner do Docker redireciona os fluxos para
    um driver de log, que o Kubernetes configura para gravar em um arquivo no
    formato JSON. Os logs são expostos pelo Kubernetes por meio do comando
    "logs" apropriadamente chamado.</para>

    <para>Por exemplo:</para>

    <programlisting>&gt;kubectl logs myesp-6476c6659b-vqckq 
&gt;0000CF0F PRG INF 2020-05-12 17:10:34.910 1 10690 "HTTP First Line: GET / HTTP/1.1" 
&gt;0000CF10 PRG INF 2020-05-12 17:10:34.911 1 10690 "GET /, from 10.240.0.4" 
&gt;0000CF11 PRG INF 2020-05-12 17:10:34.911 1 10690 “TxSummary[activeReqs=22; rcv=5ms;total=6ms;]" </programlisting>

    <para>É importante entender que esses logs são de natureza efêmera e podem
    ser perdidos se o pod for despejado, o contêiner travar, o nó morrer etc.
    Além disso, devido à natureza das soluções em contêiner, os logs
    relacionados provavelmente se originam de vários locais e pode precisar
    ser coletado e processado. É altamente recomendável desenvolver uma
    estratégia de retenção e processamento com base em suas
    necessidades.</para>

    <para>Muitas ferramentas estão disponíveis para ajudar a criar uma solução
    apropriada com base em uma abordagem do tipo "faça você mesmo" ou em
    recursos gerenciados disponíveis em provedores de nuvem.</para>

    <para>Para os ambientes mais simples, pode ser aceitável confiar no
    processo padrão do Kubernetes que encaminha todo o conteúdo de
    stdout/stderr para o arquivo. No entanto, à medida que a complexidade do
    cluster aumenta ou a importância de reter o conteúdo dos logs aumenta, uma
    arquitetura de log em nível de cluster deve ser empregada.</para>

    <para>O registro em nível de cluster para o cluster do HPCC Systems em
    contêiner pode ser realizado incluindo um agente de registro em cada nó. A
    tarefa de cada agente é expor os logs ou enviá-los por push para um
    back-end de processamento de log. Os agentes de registro geralmente não
    são fornecidos prontos para uso, mas há vários disponíveis, como o
    Elasticsearch e o Stackdriver Logging. Vários provedores de nuvem oferecem
    soluções integradas que coletam automaticamente todos os fluxos stdout/err
    e fornecem armazenamento dinâmico e ferramentas analíticas poderosas, além
    da capacidade de criar alertas personalizados com base em dados de
    log.</para>

    <para>É sua responsabilidade determinar a solução apropriada para
    processar os dados de log de streaming.</para>
  </sect1>

  <sect1 id="HPCC_LogProcessing_Solution">
    <title>Soluções de Processamento de Log</title>

    <para>Existem várias soluções de processamento de log disponíveis. Você
    pode optar por integrar os dados de registro do HPCC Systems com qualquer
    uma de suas soluções de registro existentes ou implementar outra
    especificamente para os dados do HPCC Systems. A partir do HPCC Systems
    versão 8.4, fornecemos uma solução de processamento de log leve e completa
    para sua conveniência. Como afirmado existem várias soluções possíveis,
    você deve escolher a opção que melhor atende às suas necessidades. As
    seções a seguir examinarão duas soluções possíveis.</para>

    <sect2 id="elastic4HPCC_HelmChart">
      <title>O chart Elastic4hpcclogs</title>

      <para>O HPCC Systems fornece um chart Helm gerenciado,
      <emphasis>elastic4hpcclogs</emphasis>, que utiliza os charts Elastic
      Stack Helm para Elastic Search, Filebeats e Kibana. Este gráfico
      descreve uma instância local e mínima do Elastic Stack para
      processamento de log de componentes do HPCC Systems. Depois de
      implantados com êxito, os logs de componentes do HPCC produzidos no
      mesmo namespace devem ser indexados automaticamente no ponto de
      extremidade do Elastic Search. Os usuários podem consultar esses logs
      emitindo consultas de API RESTful do Elastic Search ou por meio da
      interface do usuário do Kibana (depois de criar um padrão de índice
      simples).</para>

      <para>Pronto para uso, o Filebeat encaminha as entradas de log do
      componente HPCC para um índice com nome genérico:
      'filebeat'-&lt;VERSION&gt;- &lt;DATE_STAMP&gt; e grava os dados de log
      em campos prefixados 'hpcc.log.*'. Ele também agrega k8s, Docker e
      metadados do sistema para ajudar o usuário a consultar as entradas de
      log de seu interesse.</para>

      <para>Um padrão de índice do Kibana é criado automaticamente com base no
      layout de índice de batida de arquivo padrão.</para>
    </sect2>
  </sect1>

  <sect1 id="Installing_helm_logging_charts">
    <title>Instalando o chart elastic4hpcclogs</title>

    <para>Instalar a solução simples fornecida é, como o nome indica, simples
    e uma maneira conveniente de coletar e filtrar dados de log. Ele é
    instalado por meio de nossos gráficos de leme do repositório HPCC Systems.
    No diretório HPCC-platform/helm, o gráfico elastic4hpcclogs é fornecido
    junto com os outros componentes da plataforma HPCC Systems. As próximas
    seções mostrarão como instalar e configurar a solução Elastic stack
    logging para HPCC Systems.</para>

    <sect2 id="logs_Add_theHPCC_Systems_Repo">
      <title>Adicionar o Repositório HPCC Systems</title>

      <para>O chart Elastic for HPCC Systems entregue pode ser encontrado no
      repositório HPCC Systems Helm. Para buscar e implantar os gráficos
      gerenciados do HPCC Systems, adicione o repositório do HPCC Systems
      Helm, caso ainda não tenha feito isso:</para>

      <programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting>

      <para>Depois que esse comando for concluído com êxito, o chart
      <emphasis>elastic4hpcclogs</emphasis> estará acessível.</para>

      <para>Confirme se o chart apropriado foi puxado para baixo.</para>

      <programlisting>helm list</programlisting>

      <para>A emissão do comando helm list exibirá os gráficos e repositórios
      do HPCC Systems disponíveis. O gráfico
      <emphasis>elastic4hpcclogs</emphasis> está entre eles.</para>

      <para><graphic fileref="../../images/CL-Img01-1.jpg"/></para>
    </sect2>

    <sect2 id="Elastic4HPCC_Install_theChart">
      <title>Instalar o chart elastic4hpcc</title>

      <para>Instalar o chart <emphasis>elastic4hpcclogs</emphasis> utilizando
      o seguinte comando:</para>

      <programlisting>helm install &lt;Instance_Name&gt; hpcc/elastic4hpcclogs </programlisting>

      <para>Forneça o nome que você deseja chamar sua instância do Elastic
      Search para o parâmetro &lt;Instance_Name&gt;. Por exemplo, você poderia
      chamar sua instância de "myelk" e, nesse caso, emitiria o comando de
      instalação da seguinte maneira:</para>

      <programlisting>helm install myelk hpcc/elastic4hpcclogs </programlisting>

      <para>Após a conclusão bem-sucedida, a seguinte mensagem é
      exibida:</para>

      <programlisting>Thank you for installing elastic4hpcclogs. 
 A lightweight Elastic Search instance for HPCC component log processing. 

This deployment varies slightly from defaults set by Elastic, please review the effective values. 

PLEASE NOTE: Elastic Search declares PVC(s) which might require explicit manual removal 
  when no longer needed.
</programlisting>

      <para><informaltable colsep="1" frame="all" rowsep="1">
          <?dbfo keep-together="always"?>

          <tgroup cols="2">
            <colspec colwidth="49.50pt"/>

            <colspec/>

            <tbody>
              <row>
                <entry><inlinegraphic
                fileref="../../images/caution.png"/></entry>

                <entry><emphasis role="bold">IMPORTANTE: </emphasis> O Elastic
                Search declara PVC(s) que podem exigir remoção manual
                explícita quando não forem mais necessários. Isso pode ser
                particularmente importante para alguns provedores de nuvem que
                podem acumular custos mesmo depois de não usar mais sua
                instância. Você deve garantir que nenhum componente (como
                PVCs) persista e continue acumulando custos.</entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable></para>

      <para>OBSERVAÇÃO: dependendo da versão do Kubernetes, os usuários podem
      ser avisados sobre APIs obsoletas nos gráficos elásticos (ClusterRole e
      ClusterRoleBinding estão obsoletos na v1.17+). As implantações baseadas
      em Kubernetes &lt; v1.22 não devem ser afetadas.</para>
    </sect2>

    <sect2 id="elastic4HPCC_ConfirmingThePodsReady">
      <title>Confirmar se seus Pods estão Prontos</title>

      <para>Confirme se os pods estão prontos. Ás vezes, após instalação, os
      pods podem levar alguns segundos para aparecerem. Confirme se os pods
      estão prontos antes de proceder. Para fazer isso, use o seguinte
      comando:</para>

      <programlisting>kubectl get pods </programlisting>

      <para>Este comando retorna a seguinte informação, exibindo o status dos
      pods.</para>

      <programlisting>elasticsearch-master-0                    1/1     Running            0          
myelk-filebeat-6wd2g                      1/1     Running            0          
myelk-kibana-68688b4d4d-d489b             1/1     Running            0      </programlisting>

      <para><graphic fileref="../../images/CL-Img02-1.jpg"/></para>

      <para>Quando todos os pods estiverem indicando um estado 'ready' e
      'Running', incluindo os três componentes para filebeats, Elastic Search
      e Kibana (destacado acima), você poderá prosseguir.</para>
    </sect2>

    <sect2 id="confirming_elastic_services">
      <title>Confirmar os Serviços Elastic</title>

      <para>Para garantir que os serviços Elastic estejam em execução, entre
      com o seguinte comando:</para>

      <programlisting>$ kubectl get svc</programlisting>

      <para>Isso exibe as seguintes informações de confirmação:</para>

      <programlisting>... 
elasticsearch-master ClusterIP 10.109.50.54 &lt;none&gt; 9200/TCP,9300/TCP 68m 
elasticsearch-master-headless ClusterIP None &lt;none&gt; 9200/TCP,9300/TCP 68m 
myelk-kibana LoadBalancer 10.110.129.199 localhost 5601:31465/TCP 68m 
...</programlisting>

      <para>Nota: O serviço myelk-kibana é declarado como LoadBalancer por
      conveniência.</para>
    </sect2>

    <sect2 id="Configuring_of_Elastic_Stack_Components">
      <title>Configurando Componentes do Elastic Stack</title>

      <para>Você pode precisar ou querer personalizar os componentes do
      Elastic Stack. Os valores dos charts do componentes Elastic podem ser
      substituídos como parte do comando de implantação do HPCC Systems.
      </para>

      <para>Por exemplo:</para>

      <programlisting>helm install myelk hpcc/elastic4hpcclogs --set elasticsearch.replicas=2 </programlisting>

      <para>Consulte o repositório GitHub do Elastic Stack para obter a lista
      completa de todas as opções do Filebeat, Elastic Search, LogStash e
      Kibana com descrições.</para>
    </sect2>

    <sect2>
      <title>Use of HPCC Systems Component Logs in Kibana</title>

      <para>Uma vez ativado e em execução, você pode explorar e consultar os
      logs de componentes do HPCC Systems na interface do usuário do Kibana. O
      uso da interface do Kibana é bem suportado e documentado. Os padrões de
      índice do Kibana são necessários para explorar os dados do Elastic
      Search na interface do usuário do Kibana. A Elastic fornece explicações
      detalhadas das informações necessárias para entender e utilizar
      efetivamente a interface Elastic-Kibana. A documentação robusta do
      Kibana deve ser consultada para obter mais informações sobre como usar a
      interface do Kibana. Por favor, veja:</para>

      <para><ulink url="???">https://www.elastic.co/</ulink></para>

      <para>e</para>

      <para><ulink
      url="???">https://www.elastic.co/elastic-stack/</ulink></para>

      <para>Incluídos na documentação completa também estão vídeos de início
      rápido e outros recursos úteis.</para>
    </sect2>
  </sect1>

  <sect1 id="Azure_AKS_Insights">
    <title>Azure AKS Insights</title>

    <para>O Azure AKS Insights é um recurso opcional projetado para ajudar a
    monitorar o desempenho e a integridade de clusters baseados em Kubernetes.
    Uma vez habilitado e associado um determinado AKS a um cluster do HPCC
    Systems ativo, os logs do componente HPCC são capturados automaticamente
    pelo Insights. Todos os dados STDERR/STDOUT são capturados e
    disponibilizados para fins de monitoramento e/ou consulta. Como geralmente
    acontece com os recursos do provedor de nuvem, o custo é uma consideração
    importante e deve ser bem entendido antes da implementação. O conteúdo do
    log é gravado no armazenamento de logs associado ao seu espaço de trabalho
    do Log Analytics.</para>

    <sect2>
      <title>Habilitar Azure Insights</title>

      <para>A habilitação do Azure's Insights no cluster AKS de destino pode
      ser feita no portal do Azure ou via CLI. Para obter documentação
      detalhada do Azure: Habilite insights de contêiner: Enabling Azure's
      Insights on the target AKS cluster can be done from the Azure portal or
      via CLI. For detailed Azure documentation: Enable Container
      insights:</para>

      <para><ulink
      url="https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-onboard">https://docs.microsoft.com/en-us/azure/azure-monitor/containers/container-insights-onboard</ulink></para>

      <sect3 id="el4HPCC_EnableInsights_AzurePortal">
        <title>Portal Azure</title>

        <para>Para habilitar o insights do Azure no portal:</para>

        <para><orderedlist>
            <listitem>
              <para>Selecione cluster AKS de Destino</para>
            </listitem>

            <listitem>
              <para>Selecione Monitoring</para>
            </listitem>

            <listitem>
              <para>Selecione Insights</para>
            </listitem>

            <listitem>
              <para>Habilite - escolha ao workspace padrão</para>
            </listitem>
          </orderedlist></para>
      </sect3>

      <sect3 id="EnableInsights_CLI">
        <title>Linha de Comando</title>

        <para>Para habilitar os Azure insights na linha de comando:</para>

        <para>Opcionalmente, crie o espaço de trabalho de análise de log
        [espaço de trabalho padrão, caso contrário]</para>

        <para>Entre:</para>

        <programlisting>az monitor log-analytics workspace create -g myresourcegroup -n myworkspace --query-access Enabled </programlisting>

        <para>Habilitar no cluster AKS de destino (referência ao ID do recurso
        do workspace da etapa anterior)</para>

        <programlisting>az aks enable-addons -g myresourcegroup -n myaks -a monitoring --workspace-resource-id  \
 "/subscriptions/xyz/resourcegroups/myresourcegroup/providers/ \
  microsoft.operationalinsights/workspaces/myworkspace" </programlisting>

        <para>A interface do AKS Insights no Azure fornece visualizações de
        métricas de integridade em nível de cluster/nó/contêiner centradas em
        Kubernetes e links diretos para logs de contêiner por meio de
        interfaces de "análise de log". Os logs podem ser consultados através
        da linguagem de consulta “Kusto” (KQL). Consulte a documentação do
        Azure para obter detalhes sobre como consultar os logs.</para>

        <para>Consulte a documentação do Azure para obter detalhes sobre como
        consultar os logs.</para>

        <para>Exemplo de consulta KQL para buscar entradas de registro
        "Transaction summary" de um contêiner ECLWatch:</para>

        <programlisting>let ContainerIdList = KubePodInventory 
| where ContainerName =~ 'xyz/myesp' 
| where ClusterId =~ '/subscriptions/xyz/resourceGroups/xyz/providers/Microsoft.
                      ContainerService/managedClusters/aks-clusterxyz' 
| distinct ContainerID; 
ContainerLog 
| where LogEntry contains "TxSummary[" 
| where ContainerID in (ContainerIdList) 
| project LogEntrySource, LogEntry, TimeGenerated, Computer, Image, Name, ContainerID 
| order by TimeGenerated desc 
| render table </programlisting>

        <para>Amostra de saída</para>

        <para><graphic fileref="../../images/CL-Img03-1.jpg"/></para>

        <para>Consultas mais complexas podem ser formuladas para buscar
        informações específicas fornecidas em qualquer uma das colunas de log,
        incluindo dados não formatados na mensagem de log. A interface do
        Insights facilita a criação de alertas com base nessas consultas, que
        podem ser usadas para acionar e-mails, SMS, execução de Logic App e
        muitas outras ações.</para>
      </sect3>
    </sect2>
  </sect1>

  <sect1 id="HPCC_Systems_Application-Level_logs">
    <title>Controlando a saída de registro do HPCC Systems</title>

    <para>Os logs do HPCC Systems fornecem uma riqueza de informações que
    podem ser usadas para benchmarking, auditoria, depuração, monitoramento,
    etc. O tipo de informação fornecida nos logs e seu formato são controlados
    trivialmente através da configuração padrão do Helm. Tenha em mente que no
    modo de contêiner, cada linha de saída de log é passível de incorrer em um
    custo dependendo do provedor e do plano que você possui e a verbosidade
    deve ser cuidadosamente controlada usando as opções a seguir. Por padrão,
    os logs de componentes não são filtrados e contêm as seguintes
    colunas.</para>

    <para>Por padrão, os logs de componentes não são filtrados e contêm as
    seguintes colunas:</para>

    <programlisting>MessageID TargetAudience LogEntryClass JobID DateStamp TimeStamp ProcessId ThreadID QuotedLogMessage </programlisting>

    <para>Os logs podem ser filtrados por TargetAudience, Category ou Detail
    Level. Além disso, as colunas de saída podem ser configuradas. As
    definições de configuração de registro podem ser aplicadas no nível global
    ou de componente.</para>

    <sect2 id="Target_Audience_Filtering">
      <title>Target Audience Filtering</title>

      <para>Os públicos-alvo disponíveis incluem operador (OPR), usuário
      (USR), programador (PRO), auditoria (ADT) ou todos. O filtro é
      controlado pelo valor &lt;section&gt;.logging.audiences. O valor da
      string é composto por códigos de 3 letras delimitados pelo operador de
      agregação (+) ou pelo operador de remoção (-).</para>

      <para>Por exemplo, todas as saídas de log de componentes devem incluir
      apenas mensagens do programador e do usuário:</para>

      <programlisting>helm install myhpcc ./hpcc --set global.logging.audiences="PRO+USR" </programlisting>
    </sect2>

    <sect2 id="Target_Category_Filtering">
      <title>Filtragem de Categoria de Destino</title>

      <para>As categorias de destino disponíveis incluem desastre (DIS), erro
      (ERR), informações (INF), aviso (WRN), progresso (PRO), métricas (MET).
      O filtro de categoria (ou classe) é controlado pelo valor
      &lt;section&gt;.logging.classes, composto por códigos de 3 letras
      delimitados pelo operador de agregação (+) ou pelo operador de remoção
      (-).</para>

      <para>Por exemplo, a saída do log da instância mydali para incluir todas
      as classes, exceto o progresso:</para>

      <programlisting>helm install myhpcc ./hpcc --set dali[0].logging.classes="ALL-PRO" --set dali[0].name="mydali" </programlisting>
    </sect2>

    <sect2 id="Log_Detail_Level_Configuration">
      <title>Log Detail Level Configuration</title>

      <para>A verbosidade da saída do log pode ser ajustada de "critical
      messages only" (1) até "report all messages" (100). O nível de log
      padrão é bastante alto (80) e deve ser ajustado de acordo.</para>

      <para>Por exemplo, a verbosidade deve ser média para todos os
      componentes:</para>

      <programlisting>helm install myhpcc ./hpcc --set global.logging.detail="50" </programlisting>
    </sect2>

    <sect2 id="Log_Data_Column_Configuration">
      <title>Configuração da Coluna de Dados de Registro</title>

      <para>As colunas de dados de log disponíveis incluem messageid(MID),
      público(AUD), class(CLS), date(DAT), time(TIM), node(NOD),
      militime(MLT), microtime(MCT), nanotime(NNT) , processid(PID),
      threadid(TID), job(JOB), use(USE), session(SES), code(COD),
      component(COM), quotemessage(QUO), prefix(PFX), all(ALL) e padrão (STD).
      A configuração das colunas (ou campos) de dados de log é controlada pelo
      valor &lt;section&gt;.logging.fields, composto por códigos de 3 letras
      delimitados pelo operador de agregação (+) ou pelo operador de remoção
      (-). Por exemplo, todas as saídas de log de componentes devem incluir as
      colunas padrão, exceto a coluna de ID do job:</para>

      <para>Por exemplo, todas as saídas de log de componentes devem incluir
      as colunas padrão, exceto a coluna de ID do job:</para>

      <programlisting>helm install myhpcc ./hpcc --set global.logging.fields="STD-JOB" </programlisting>

      <para>O ajuste de valores de registro por componente pode exigir a
      afirmação de vários valores específicos de componentes, o que pode ser
      inconveniente de fazer por meio do parâmetro de linha de comando --set.
      Nesses casos, um arquivo de valores personalizados pode ser usado para
      definir todos os campos obrigatórios.</para>

      <para>Por exemplo, a instância do componente ESP 'eclwatch' deve gerar
      um log mínimo:</para>

      <programlisting>helm install myhpcc ./hpcc --set -f ./examples/logging/esp-eclwatch-low-logging-values.yaml</programlisting>
    </sect2>
  </sect1>
</chapter>
