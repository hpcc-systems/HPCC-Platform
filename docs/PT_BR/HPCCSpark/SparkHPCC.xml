<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<book xml:base="../">
  <bookinfo>
    <title>HPCC / Conector do Spark</title>

    <mediaobject>
      <imageobject>
        <imagedata fileref="images/redswooshWithLogo3.jpg"/>
      </imageobject>
    </mediaobject>

    <author>
      <surname>Equipe de documentação de Boca Raton</surname>
    </author>

    <legalnotice>
      <para>Sua opinião e comentários sobre este documento são muito
      bem-vindos e podem ser enviados por e-mail para
      <email>docfeedback@hpccsystems.com</email></para>

      <para>Inclua a frase <emphasis role="bold">Feedback sobre
      documentação</emphasis> na linha de assunto e indique o nome do
      documento, o número das páginas e número da versão atual no corpo da
      mensagem.</para>

      <para>LexisNexis e o logotipo Knowledge Burst são marcas comerciais
      registradas da Reed Elsevier Properties Inc., usadas sob licença.</para>

      <para>HPCC Systems<superscript>®</superscript> é uma marca registrada da
      LexisNexis Risk Data Management Inc.</para>

      <para>Os demais produtos, logotipos e serviços podem ser marcas
      comerciais ou registradas de suas respectivas empresas.</para>

      <para>Todos os nomes e dados de exemplo usados neste manual são
      fictícios. Qualquer semelhança com pessoas reais, vivas ou mortas, é
      mera coincidência.</para>

      <para/>
    </legalnotice>

    <xi:include href="common/Version.xml" xpointer="FooterInfo"
                xmlns:xi="http://www.w3.org/2001/XInclude"/>

    <xi:include href="common/Version.xml" xpointer="DateVer"
                xmlns:xi="http://www.w3.org/2001/XInclude"/>

    <corpname>HPCC Systems<superscript>®</superscript></corpname>

    <xi:include href="common/Version.xml" xpointer="Copyright"
                xmlns:xi="http://www.w3.org/2001/XInclude"/>

    <mediaobject role="logo">
      <imageobject>
        <imagedata fileref="images/LN_Rightjustified.jpg"/>
      </imageobject>
    </mediaobject>
  </bookinfo>

  <chapter>
    <title>O conector Spark HPCC Systems</title>

    <sect1 id="overview" role="nobrk">
      <title>Visão geral</title>

      <para>O conector distribuído Spark-HPCCSystems é uma biblioteca Java que
      facilita o acesso de um cluster do Spark aos dados armazenados em um
      cluster do HPCC Systems. A biblioteca de conectores emprega o recurso de
      leitura de arquivos remotos padrão do HPCC Systems para ler dados de
      conjuntos de datasets sequenciais ou indexados do HPCC.</para>

      <para>Os dados em um cluster HPCC são particionados horizontalmente, com
      dados em cada nó do cluster. Depois de configurados, os dados do HPCC
      estão disponíveis para acesso em paralelo pelo cluster do Spark.</para>

      <para>No repositório do GitHub (<ulink
      url="https://github.com/hpcc-systems/Spark-HPCC">https://github.com/hpcc-systems/Spark-HPCC</ulink>)
      você pode encontrar o código-fonte e exemplos. Existem vários artefatos
      na pasta DataAccess/src/main/java de interesse primário. A classe
      <emphasis>org.hpccsystems.spark.HpccFile</emphasis> é a fachada de um
      arquivo em um cluster HPCC. O
      <emphasis>org.hpccsystems.spark.HpccRDD</emphasis> é um dataset
      distribuído resiliente derivado dos dados no cluster HPCC e é criado
      pelo método
      <emphasis>org.hpccsystems.spark.HpccFile.getRDD</emphasis>(…). A classe
      <emphasis>HpccFile</emphasis> suporta o carregamento de dados para
      construir um objeto <emphasis>Dataset &lt;Row&gt;</emphasis> para a
      interface Spark . Isso primeiro carregará os dados em um RDD &lt;Row&gt;
      e, em seguida, converterá esse RDD em um DataSet &lt;Row&gt; por meio
      dos mecanismos internos do Spark.</para>

      <para>Existem vários artefatos adicionais de algum interesse. A classe
      <emphasis>org.hpccsystems.spark.ColumnPruner</emphasis> é fornecida para
      permitir a recuperação somente das colunas de interesse do cluster HPCC.
      O artefato <emphasis>targetCluster</emphasis> permite especificar o
      cluster HPCC no qual o arquivo de destino existe. A classe
      <emphasis>org.hpccsystems.spark.thor.FileFilter</emphasis> é fornecida
      para facilitar a filtragem de registros de interesse do cluster
      HPCC.</para>

      <para>O repositório git inclui dois exemplos na pasta
      Examples/src/main/scala folder. Os exemplos
      (<emphasis>org.hpccsystems.spark_examples.Dataframe_Iris_LR</emphasis> e
      <emphasis>org.hpccsystems.spark_examples.Iris_LR</emphasis>) são Scala
      Objects com uma função main(). Ambos os exemplos usam o dataset clássico
      da Iris. O dataset pode ser obtido de uma variedade de fontes, incluindo
      o repositório HPCC-Systems/ecl-ml. IrisDs.ecl (pode ser encontrado na
      pasta ML/Tests/Explanatory: <ulink
      url="https://github.com/hpcc-systems/Spark-HPCC/blob/master/Examples/src/main/ecl/IrisDS.ecl">https://github.com/hpcc-systems/Spark-HPCC/blob/master/Examples/src/main/ecl/IrisDS.ecl</ulink>)
      pode ser executado para gerar o dataset Iris no HPCC. Um passo a passo
      dos exemplos é fornecido na seção Exemplos.</para>

      <para>O conector distribuído Spark-HPCCSystems também suporta o PySpark.
      Ele usa as mesmas classes/API que o Java.</para>

      <para>
        <informaltable colsep="1" frame="all" rowsep="1">
          <?dbfo keep-together="always"?>

          <tgroup cols="2">
            <colspec colwidth="49.50pt"/>

            <colspec/>

            <tbody>
              <row>
                <entry>
                  <graphic fileref="images/tip.jpg"/>
                </entry>

                <entry>
                  <para>Como é comum na comunicação do cliente Java por TLS,
                  os conectores Spark-HPCC direcionados a um cluster HPCC por
                  TLS precisarão importar os certificados apropriados para o
                  keystore Java local.</para>

                  <para/>

                  <para>*Uma maneira de fazer isso é usar o keytool fornecido
                  com as instalações Java. Consulte a documentação do keytool
                  para uso.</para>
                </entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable>
      </para>

      <sect2>
        <title>Integração Spark</title>

        <para>O plug-in Spark integrado ao HPCC não é mais compatível a partir
        da versão 9.0.0 em favor de clusters Spark autônomos gerenciados pelo
        usuário vinculados à plataforma HPCC usando o conector
        Spark-HPCC.</para>
      </sect2>

      <sect2 role="brk">
        <title>Considerações Especiais</title>

        <sect3>
          <title>Estouro de valor não assinado</title>

          <para>Java não suporta um tipo de inteiro não assinado, portanto, a
          leitura de valores UNSIGNED8 dos dados do HPCC pode causar um
          estouro de inteiro em Java. Os valores de UNSIGNED8 são
          frequentemente usados como identificadores exclusivos em datasets,
          caso em que o overflow seria aceitável, pois o valor do
          transbordamento ainda será exclusivo.</para>

          <para>O conector Spark-HPCC permite que os valores não assinados
          sejam excedidos em Java e não relatará uma exceção. O chamador é
          responsável por interpretar o valor com base no sinalizador recef
          <emphasis role="bold">isunsigned</emphasis>.</para>
        </sect3>
      </sect2>
    </sect1>

    <sect1 id="primary-classes">
      <title>Classes Primárias</title>

      <para>A classe <emphasis>HpccFile</emphasis> e as classes
      <emphasis>HpccRDD</emphasis> são discutidas em mais detalhes abaixo.
      Essas são as classes principais usadas para acessar dados de um cluster
      HPCC. A classe <emphasis>HpccFile</emphasis> suporta o carregamento de
      dados para construir um objeto <emphasis>Dataset &lt;Row&gt;</emphasis>
      para a interface Spark. Isso primeiro carregará os dados em um RDD
      &lt;Row&gt; e, em seguida, converterá esse RDD em um DataSet &lt;Row&gt;
      por meio dos mecanismos internos do Spark.</para>

      <para>A classe <emphasis>org.hpccsystems.spark.HpccFile</emphasis>
      possui vários construtores. Todos os construtores recebem informações
      sobre o cluster e o nome do dataset de interesse. As classes JAPI
      WS-Client são usadas para acessar informações detalhadas do arquivo. Uma
      definição usada para selecionar as colunas a serem retornadas e uma
      definição para selecionar as linhas a serem retornadas também podem ser
      fornecidas. Eles são discutidos na seção <emphasis>Classes Adicionais de
      Interesse</emphasis> abaixo. A classe tem dois métodos de interesse
      primário: o método <emphasis>getRDD(…)</emphasis> e o método
      <emphasis>getDataframe(…)</emphasis> , que são ilustrados na seção
      <emphasis>Exemplo</emphasis>.</para>

      <para>O método <emphasis>getRecordDefinition()</emphasis> da classe
      <emphasis>HpccFile</emphasis> pode ser usado para recuperar uma
      definição do arquivo. O método <emphasis>getFileParts()</emphasis> pode
      ser usado para ver como o arquivo é particionado no cluster HPCC. Esses
      métodos retornam as mesmas informações que podem ser encontradas na aba
      DEF da página de detalhes do dataset do ECL Watch e na aba PARTS
      respectivamente.</para>

      <para>A classe <emphasis>org.hpccsystems.spark.HpccRDD</emphasis>
      estende a classe de modelo <emphasis>RDD&lt;Record&gt;</emphasis>. A
      classe emprega a <emphasis>org.hpccsystems.spark.HpccPart</emphasis>
      para as partições Spark. A classe
      <emphasis>org.hpccsystems.spark.Record</emphasis> é usada como o
      contêiner para os campos do cluster HPCC. A classe
      <emphasis>Record</emphasis>pode criar uma instância
      <emphasis>Row</emphasis> com um esquema.</para>

      <para>Os objetos de partição <emphasis>HpccRDD</emphasis> HpccPart leem
      cada um blocos de dados do cluster HPCC independentemente uns dos
      outros. A leitura inicial busca o primeiro bloco de dados, solicita o
      segundo bloco de dados e retorna o primeiro registro. Quando o bloco
      estiver esgotado, o próximo bloco deverá estar disponível no soquete e
      uma nova solicitação de leitura será emitida.</para>

      <para>O <emphasis>HpccFileWriter</emphasis> é outra classe primária
      usada para gravar dados em um cluster HPCC. Tem um único construtor com
      a seguinte assinatura:</para>

      <programlisting>public HpccFileWriter(String connectionString, String user, String pass) 
throws Exception { </programlisting>

      <para>O primeiro parâmetro <emphasis>connectionString</emphasis> contém
      as mesmas informações que o <emphasis>HpccFile</emphasis>. Deve estar no
      seguinte formato: {http|https}://{ECLWATCHHOST}:{ECLWATCHPORT}</para>

      <para>O construtor tentará se conectar ao HPCC. Esta conexão será então
      usada para quaisquer chamadas subsequentes para o
      <emphasis>saveToHPCC</emphasis>.</para>

      <programlisting>public long saveToHPCC(SparkContext sc, RDD&lt;Row&gt; scalaRDD, String clusterName, 
                        String fileName) throws Exception {</programlisting>

      <para>O método <emphasis>saveToHPCC</emphasis> suporta apenas os tipos
      RDD&lt;row&gt;. Você pode precisar modificar sua representação de dados
      para usar essa funcionalidade. No entanto, essa representação de dados é
      usada pelo Spark SQL e pelo HPCC. Isso só é suportado gravando em uma
      configuração co-localizada. Assim, o Spark e o HPCC devem ser instalados
      nos mesmos nós. A leitura suporta apenas a leitura de dados de um
      cluster HPCC remoto.</para>

      <para>O <emphasis>clusterName</emphasis>, conforme usado no caso acima,
      é o cluster desejado para gravar dados, por exemplo, no cluster Thor
      "mitor". Atualmente, há suporte apenas para gravação em clusters do
      Thor. A gravação em um cluster Roxie não é suportada e retornará uma
      exceção. O nome do arquivo usado no exemplo acima está no formato HPCC ,
      por exemplo: "~example::text".</para>

      <para>Internamente, o método saveToHPCC gerará múltiplos jobs do Spark.
      Atualmente, isso gera dois jobs. O primeiro job mapeia o local das
      partições no cluster do Spark para fornecer essas informações ao HPCC. O
      segundo job faz a gravação real dos arquivos. Há também algumas chamadas
      internamente ao ESP para lidar com coisas como iniciar o processo de
      gravação amando <emphasis>DFUCreateFile</emphasis> e publicar o arquivo
      depois de ter sido escrito chamando
      <emphasis>DFUPublishFile</emphasis>.</para>

      <sect2 role="brk">
        <title>Using the Spark Datasource API to Read and Write</title>

        <para>Example Python code:</para>

        <para>
          <programlisting># Connect to HPCC and read a file
df = spark.read.load(format="hpcc",
                     host="127.0.0.1:8010",
                     password="",
                     username="",
                     limitPerFilePart=100,        
                                      # Limit the number of rows to read from each file part
                     projectList="field1, field2, field3.childField1",     
                                      # Comma separated list of columns to read
                     fileAccessTimeout=240,
                     path="example::file")
# Write the file back to HPCC
df.write.save(format="hpcc",
              mode="overwrite",        
                   # Left blank or not specified results in an error if the file exists
              host="127.0.0.1:8010",
              password="",
              username="",
              cluster="mythor",
              path="example::file")</programlisting>
        </para>

        <para>Exemplo de código Scala:</para>

        <para>
          <programlisting>// Read a file from HPCC
val dataframe = spark.read.format("hpcc")
                .option("host","127.0.0.1:8010")
                .option("password", "")
                .option("username", "")
                .option("limitPerFilePart",100)
                .option("fileAccessTimeout",240)
                .option("projectList","field1, field2, field3.childField")
                .load("example::file")
// Write the dataset back
   dataframe.write.mode("overwrite")
                   .format("hpcc")
                   .option("host","127.0.0.1:8010")
                   .option("password", "")
                   .option("username", "")
                   .option("cluster","mythor")
                   .save("example::file")</programlisting>
        </para>

        <para>Exemplo de código R:</para>

        <para>
          <programlisting>df &lt;- read.df(source = "hpcc",
              host = "127.0.0.1:8010",
              path = "example::file",
              password = "",
              username = "",
              limitPerFilePart = 100,
              fileAccessTimeout = 240,
              projectList = "field1, field2, field3.childField")
write.df(df, source = "hpcc",
             host = "127.0.0.1:8010",
             cluster = "mythor",
             path = "example::file",
             mode = "overwrite",
             password = "",
             username = "",
             fileAccessTimeout = 240)</programlisting>
        </para>
      </sect2>
    </sect1>

    <sect1 id="additional-classes-of-interest">
      <title>Classes Adicionais de Interesse</title>

      <para>As principais classes de interesse para esta seção são a remoção
      de colunas e a filtragem de arquivos. Além disso, há uma classe auxiliar
      para remapear informações de IP quando necessário, e isso também é
      discutido abaixo.</para>

      <para>As informações de seleção da coluna são fornecidas como uma string
      para o objeto <emphasis>org.hpccsystems.spark.ColumnPruner</emphasis> A
      string é uma lista de nomes de campos separados por vírgulas. Um campo
      de interesse pode conter um conjunto de dados de linha ou filho e a
      notação de nome pontilhada é usada para oferecer suporte à seleção de
      campos filho individuais. O <emphasis>ColumnPruner</emphasis> analisa a
      cadeia em uma instância da classe <emphasis>TargetColumn</emphasis> raiz
      que contém as colunas de destino de nível superior. Um
      <emphasis>TargetColumn</emphasis> pode ser um campo simples ou pode ser
      um conjunto de dados filho e, portanto, ser um objeto raiz para o layout
      do registro filho.</para>

      <para>O filtro de linha é implementado na classe
      <emphasis>org.hpccsystems.spark.thor.FileFilter</emphasis>. Uma
      instância de <emphasis>FileFilter</emphasis> é restrita a partir de uma
      matriz de objetos
      <emphasis>org.hpccsystems.spark.thor.FieldFilter</emphasis>. Cada
      instância de <emphasis>FieldFilter</emphasis> é composta de um nome de
      campo (em notação pontuada para nomes compostos) e uma matriz de objetos
      <emphasis>org.hpccsystems.spark.thor.FieldFilterRange</emphasis> . Cada
      instância de <emphasis>FieldFilterRange</emphasis> pode ser um intervalo
      aberto, ou fechado ou um valor único. O registro é selecionado quando
      pelo menos um <emphasis>FieldFilterRange</emphasis> corresponde para
      cada uma das instâncias do <emphasis>FieldFilter</emphasis> na
      matriz.</para>

      <para>Os valores <emphasis>FieldFilterRange</emphasis> podem ser cadeias
      ou números. Existem métodos fornecidos para construir os seguintes
      testes de intervalo: igual, não igual, menor que, menor que ou igual a,
      maior que, e maior que ou igual a. Além disso, um teste de inclusão de
      conjunto é suportado para cadeias de caracteres. Se o arquivo for um
      índice, os campos de filtro, que são campos-chave, são utilizados para
      uma pesquisa de índice. Qualquer campo de filtro não mencionado é
      tratado como desconhecido.</para>

      <para>A arquitetura de implantação usual para os Clusters HPCC consiste
      em uma coleção de nós em uma rede. As informações de gerenciamento de
      arquivos incluem os endereços IP dos nós que contêm as partições do
      arquivo. As classes do conector Spark-HPCC usam esses endereços IP para
      estabelecer conexões de soquete para a leitura remota. Um cluster HPCC
      pode ser implantado como um cluster virtual com endereços IP privados.
      Isso funciona para os componentes do cluster porque eles estão todos na
      mesma LAN privada. No entanto, os nós do cluster Spark podem não estar
      na mesma LAN. Nesse caso, a classe
      <emphasis>org.hpccsystems.spark.RemapInfo</emphasis> é usada para
      definir as informações necessárias para alterar o endereçamento. Existem
      duas opções que podem ser usadas. A primeira opção é que cada nó de
      trabalho do Thor pode receber um IP visível para o cluster do Spark.
      Esses endereços devem ser um intervalo contíguo. A segunda opção é
      atribuir um IP e um intervalo contíguo de números de porta. O objeto
      <emphasis>RemapInfo</emphasis> é fornecido como um parâmetro.</para>
    </sect1>

    <para>Fornecemos alguns exemplos de utilização de um ambiente Spark. Os
    exemplos fornecidos dependem do shell Spark..</para>

    <para>Você pode encontrar exemplos no repositório do Github:</para>

    <para>
      <ulink
      url="https://github.com/hpcc-systems/Spark-HPCC/tree/master/Examples">https://github.com/hpcc-systems/Spark-HPCC/tree/master/Examples</ulink>
    </para>
  </chapter>
</book>
