<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE sect1 PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<sect1 id="IntroHDFS" role="nobrk">
  <!-- DNT-Start --><title>Introduction</title><!-- DNT-End -->

  <para>The <!-- DNT-Start -->HDFS<!-- DNT-End --> to <!-- DNT-Start -->HPCC<!-- DNT-End --> Connector provides a means to import data from
  Hadoop's <!-- DNT-Start -->HDFS<!-- DNT-End --> into an <!-- DNT-Start -->HPCC<!-- DNT-End --> Systems<superscript>Â®</superscript> Thor
  platform. It also supports exporting the data back to <!-- DNT-Start -->HDFS<!-- DNT-End --> or exporting and
  merging it. This allows you to use an <!-- DNT-Start -->HPCC<!-- DNT-End --> cluster in conjunction with your
  Hadoop-based cluster.</para>

  <para>The H2H Connector is an add-on to an <!-- DNT-Start -->HPCC<!-- DNT-End --> Cluster and consists of
  server-side components and <!-- DNT-Start -->ECL<!-- DNT-End --> Macros that invoke them.</para>

  <para><itemizedlist>
      <listitem>
        <para><emphasis role="bold">Server-side
        components:</emphasis><itemizedlist>
            <listitem>
              <para>The executable ( /opt/HPCCSystems/bin/hdfsconnector
              )</para>
            </listitem>

            <listitem>
              <para>The shell script (/opt/HPCCSystems/bin/hdfspipe)</para>
            </listitem>

            <listitem>
              <para>The configuration file
              (/opt/HPCCSystems/etc/HPCCSystems/hdfsconnector.conf)</para>

              <para>The configuration file contains the location where Hadoop
              is installed, as shown in the example below: </para>

              <!-- DNT-Start --><programlisting>HADOOP_LOCATION=/usr/local/hadoop</programlisting><!-- DNT-End -->

              <para>This allows access to the libhdfs (<!-- DNT-Start -->API<!-- DNT-End -->) library.</para>

              <variablelist>
                <varlistentry>
                  <term>Note:</term>

                  <listitem>
                    <para>The <!-- DNT-Start -->HDFS<!-- DNT-End --> Connector writes log files to a folder
                    named <emphasis
                    role="bluebold">mydataconnectors</emphasis> in the the
                    <!-- DNT-Start -->HPCC<!-- DNT-End --> log directory (the <!-- DNT-Start -->HPCC<!-- DNT-End --> log location can be set using
                    Configuration Manager). </para>

                    <para>The default location is:<programlisting>/var/log/HPCCSystems/mydataconnectors/</programlisting></para>

                    <para>The log files are written following the following
                    pattern:<programlisting>HDFSCONNECTOR.&lt;nodeid&gt;.&lt;PID&gt;.log</programlisting></para>
                  </listitem>
                </varlistentry>
              </variablelist>
            </listitem>
          </itemizedlist></para>
      </listitem>

      <listitem>
        <para><emphasis role="bold"><!-- DNT-Start -->ECL<!-- DNT-End --> Macros
        (HDFSConnector.ecl)</emphasis></para>

        <itemizedlist>
          <listitem>
            <para>HDFSConnector.PipeIn</para>

            <para>Imports data from Hadoop's file system (<!-- DNT-Start -->HDFS<!-- DNT-End -->) to a Thor
            Cluster.</para>
          </listitem>

          <listitem>
            <para>HDFSConnector.PipeOut</para>

            <para>Exports data from a Thor Cluster to Hadoop's file system
            (<!-- DNT-Start -->HDFS<!-- DNT-End -->).</para>
          </listitem>

          <listitem>
            <para>HDFSConnector.PipeOutAndMerge</para>

            <para>Exports data from a Thor Cluster to Hadoop's file system
            (<!-- DNT-Start -->HDFS<!-- DNT-End -->) and merges the data.</para>
          </listitem>
        </itemizedlist>
      </listitem>

      <listitem>
        <para>The <!-- DNT-Start -->HDFS<!-- DNT-End --> to <!-- DNT-Start -->HPCC<!-- DNT-End --> Connector User's Guide</para>
      </listitem>
    </itemizedlist></para>
</sect1>
