<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE sect1 PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<sect1 id="PIPEIN" role="nobrk">
  <!-- DNT-Start --><title>HDFSConnector.PipeIn</title><!-- DNT-End -->

  <para><emphasis role="bold">HDFSConnector.PipeIn </emphasis><emphasis>(
  <!-- DNT-Start -->ECL<!-- DNT-End -->_<!-- DNT-Start -->RS<!-- DNT-End -->, HadoopFileName, Layout, HadoopFileFormat, HDFSHost, HDFSPort
  )</emphasis></para>

  <para><informaltable colsep="0" frame="none" rowsep="0">
      <tgroup cols="2">
        <colspec colwidth="150pt" />

        <colspec />

        <tbody>
          <row>
            <entry><!-- DNT-Start --><emphasis>ECL_RS</emphasis><!-- DNT-End --></entry>

            <entry>The <!-- DNT-Start -->ECL<!-- DNT-End --> recordset definition name to generate.</entry>
          </row>

          <row>
            <entry><!-- DNT-Start --><emphasis>HadoopFileName</emphasis><!-- DNT-End --></entry>

            <entry>The Hadoop data file name as it exists in the <!-- DNT-Start -->HDFS<!-- DNT-End -->.</entry>
          </row>

          <row>
            <entry><!-- DNT-Start --><emphasis>Layout</emphasis><!-- DNT-End --></entry>

            <entry>The <!-- DNT-Start -->ECL<!-- DNT-End --> <!-- DNT-Start -->RECORD<!-- DNT-End --> structure representing the structure of the
            Hadoop data.</entry>
          </row>

          <row>
            <entry><!-- DNT-Start --><emphasis>HadoopFileFormat</emphasis><!-- DNT-End --></entry>

            <entry>The Hadoop data file format : <!-- DNT-Start -->FLAT<!-- DNT-End --> | <!-- DNT-Start -->CSV<!-- DNT-End -->.</entry>
          </row>

          <row>
            <entry><!-- DNT-Start --><emphasis>HDFSHost</emphasis><!-- DNT-End --></entry>

            <entry>The Hadoop <!-- DNT-Start -->DFS<!-- DNT-End --> host name or <!-- DNT-Start -->IP<!-- DNT-End --> address.</entry>
          </row>

          <row>
            <entry><!-- DNT-Start --><emphasis>HDFSPort</emphasis><!-- DNT-End --></entry>

            <entry>The Hadoop NameNode port number.</entry>
          </row>
        </tbody>
      </tgroup>
    </informaltable></para>

  <para>The <emphasis role="bold">HDFSConnector.PipeIn </emphasis>macro is
  called to pipe in data from the Hadoop file system (<!-- DNT-Start -->HDFS<!-- DNT-End -->) to a Thor
  Cluster.</para>

  <para>Example:</para>

  <!-- DNT-Start --><programlisting>#OPTION('pickBestEngine', 0);
IMPORT std;
IMPORT DataConnectors;
Layout_Flat := RECORD
  STRING10  fname;
  STRING10  lname;
  UNSIGNED1 prange;
  STRING10  street;
  UNSIGNED1 zips;
  UNSIGNED1 age;
  STRING2   birth_state;
  STRING3   birth_month;
  UNSIGNED1 one;
  UNSIGNED8 id;
END;
DataConnectors.HDFSConnector.PipeIn(MyDataFile, 
                           '/user/hadoop/test/MyData1', 
                           Layout_Flat, FLAT, 
                           '192.168.56.120', 
                           54310);
OUTPUT(MyDataFile);
</programlisting><!-- DNT-End -->

  <?hard-pagebreak ?>

  <!-- DNT-Start --><programlisting>#OPTION('pickBestEngine', 0);
IMPORT std;
IMPORT DataConnectors;
Layout_CSV := RECORD
  STRING10 fname;
  STRING10 lname;
  STRING3  prange;
  STRING10 street;
  STRING5  zips;
  STRING3  age;
  STRING2  birth_state;
  STRING3  birth_month;
  STRING3  one;
  STRING20 id;
END;
DataConnectors.HDFSConnector.PipeIn(MyDataFile, 
                           '/user/Administrator/test/MyData1', 
                           Layout_CSV, CSV(SEPARATOR('|')), 
                           '192.168.56.120', 
                           54310);
OUTPUT(MyDataFile);
</programlisting><!-- DNT-End -->

  <para></para>
</sect1>
