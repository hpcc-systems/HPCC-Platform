<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE chapter PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
"http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<chapter id="CustomConfig">
  <title>Customizing Configurations</title>

  <sect1 id="CustTechniques" role="nobrk">
    <title>Customization Techniques</title>

    <para>This section walks through creating a customized configuration YAML
    file and deploying an HPCC Systems<superscript>®</superscript> platform
    using the default configuration plus the customizations. Once you
    understand the concepts in this chapter, you can refer to the next chapter
    for a reference to all configuration value settings.</para>

    <para>There are several ways to customize a platform deployment. We
    recommend using methods that allow you to best take advantage of the
    configuration as code (CaC) practices. Configuration as code is the
    standard of managing configuration files in a version control system or
    repository.</para>

    <para>The following is a list of common customization techniques:</para>

    <itemizedlist>
      <listitem>
        <para>The first way to override a setting in the default configuration
        is via the command line using the <emphasis
        role="bold">--set</emphasis> parameter.</para>

        <para>This is the easiest, but the least compliant with CaC
        guidelines. It is also harder to keep track of overrides this
        way.</para>
      </listitem>

      <listitem>
        <para>The second way is to modify the default values saved using a
        command like:</para>

        <programlisting>helm show values hpcc/hpcc &gt; myvalues.yaml</programlisting>

        <para>This could comply with CaC guidelines if you place that file
        under version control, but it makes it harder to utilize a newer
        default configuration when one becomes available.</para>
      </listitem>

      <listitem>
        <para>The third way, is the one we typically use. Use the default
        configuration plus a customization YAML file and use the -f parameter
        (or --values parameter) to the helm command. This uses the default
        configuration and only overrides the settings specified in the
        customization YAML. In addition, you can pass multiple YAML files in
        the same command, if desired.</para>

        <para>You can also use the -f option to pass a YAML file using a URL.
        For example:</para>

        <para><programlisting>helm install mycluster hpcc/hpcc -f https://raw.githubusercontent.com/JD/MyHelm/main/noroxie.yaml</programlisting></para>

        <para>For this tutorial, we will use the third method to stand up a
        platform with all the default settings but add some customizations. In
        the first example, instead of one Roxie, it will have two. In the
        second example, it will add a second 10-way Thor.</para>
      </listitem>
    </itemizedlist>

    <sect2 id="CustTutorial1" role="brk">
      <title>Create a Custom Configuration Chart for Two Roxies</title>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">tworoxies.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Save the default values to a text file:</para>

          <para><programlisting>helm show values hpcc/hpcc &gt; myvalues.yaml</programlisting></para>
        </listitem>

        <listitem>
          <para>Open the saved file (myvalues.yaml) in a text editor.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">roxie:</emphasis>
          section and paste it into the new tworoxies.yaml file.</para>
        </listitem>

        <listitem>
          <para>Copy the entire contents of the new tworoxies.yaml file,
          except the first line (roxie:), and paste it at the end of the
          file.</para>
        </listitem>

        <listitem>
          <para>In the second block, edit the value for <emphasis
          role="bold">name:</emphasis> and change it to <emphasis
          role="bold">roxie2.</emphasis></para>
        </listitem>

        <listitem>
          <para>In the second block, edit the value for <emphasis
          role="bold">prefix:</emphasis> and change it to <emphasis
          role="bold">roxie2.</emphasis></para>
        </listitem>

        <listitem>
          <para>In the second block, edit the value for <emphasis
          role="bold">name:</emphasis> under <emphasis
          role="bold">services:</emphasis> and change it to <emphasis
          role="bold">roxie2</emphasis>.</para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>

          <para>The resulting tworoxies.yaml file should look like this</para>

          <para><emphasis role="bold">Note:</emphasis> The comments have been
          removed to simplify the example:</para>

          <para><programlisting>roxie:
- name: roxie
  disabled: false
  prefix: roxie
  services:
  - name: roxie
    servicePort: 9876
    listenQueue: 200
    numThreads: 30
    visibility: local
  replicas: 2  
  numChannels: 2
  serverReplicas: 0
  localAgent: false
  traceLevel: 1
  topoServer:
    replicas: 1

- name: roxie2
  disabled: false
  prefix: roxie2
  services:
  - name: roxie2
    servicePort: 9876
    listenQueue: 200
    numThreads: 30
    visibility: local
  replicas: 2  
  numChannels: 2
  serverReplicas: 0
  localAgent: false
  traceLevel: 1
  topoServer:
    replicas: 1
</programlisting></para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          tworoxies.yaml file.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting>helm install mycluster hpcc/hpcc -f tworoxies.yaml</programlisting></para>
        </listitem>

        <listitem>
          <para>After you confirm that your deployment is running, open ECL
          Watch.</para>

          <para>You should see two Roxie clusters available as Targets --
          roxie and roxie2.</para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 id="CustTutorial2" role="nobrk">
      <title>Create a Custom Configuration Chart for Two Thors</title>

      <para>You can specify more than one custom configuration by repeating
      the -f parameter.</para>

      <para>For example:</para>

      <para><programlisting>helm install mycluster hpcc/hpcc  -f tworoxies.yaml -f twothors.yaml</programlisting></para>

      <para>In this section, we will add a second 10-way Thor.</para>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">twothors.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Open the default values file that you saved earlier
          (myvalues.yaml) in a text editor.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">thor:</emphasis> section
          and paste it into the new twothors.yaml file.</para>
        </listitem>

        <listitem>
          <para>Copy the entire contents of the new twothors.yaml file, except
          the first line (thor:), and paste it at the end of the file.</para>
        </listitem>

        <listitem>
          <para>In the second block, edit the value for <emphasis
          role="bold">name:</emphasis> and change it to <emphasis
          role="bold">thor10.</emphasis></para>
        </listitem>

        <listitem>
          <para>In the second block, edit the value for <emphasis
          role="bold">prefix:</emphasis> and change it to <emphasis
          role="bold">thor10.</emphasis></para>
        </listitem>

        <listitem>
          <para>In the second block, edit the value for <emphasis
          role="bold">numWorkers:</emphasis> and change it to <emphasis
          role="bold">10.</emphasis></para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>

          <para>The resulting twothors.yaml file should look like this</para>

          <para><emphasis role="bold">Note:</emphasis> The comments have been
          removed to simplify the example:</para>

          <para><programlisting>thor:
- name: thor
  prefix: thor
  numWorkers: 2
  maxJobs: 4
  maxGraphs: 2
- name: thor10
  prefix: thor10
  numWorkers: 10
  maxJobs: 4
  maxGraphs: 2</programlisting></para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          twothors.yaml file.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting># If you have previously stopped your cluster

helm install mycluster hpcc/hpcc -f tworoxies.yaml -f twothors.yaml

# To upgrade without stopping

helm upgrade mycluster hpcc/hpcc -f tworoxies.yaml -f twothors.yaml
</programlisting></para>
        </listitem>

        <listitem>
          <para>After you confirm that your deployment is running, open ECL
          Watch.</para>

          <para>You should see two Thor clusters available as Targets -- thor
          and thor10.</para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 id="HelmAllowPipeProgramsThor" role="nobrk">
      <title>Create a Custom Configuration Chart to AllowPipePrograms</title>

      <para>You can specify more than one custom configuration by repeating
      the -f parameter.</para>

      <para>For example:</para>

      <para><programlisting>helm install mycluster hpcc/hpcc  -f tworoxies.yaml -f thorWithPipe.yaml</programlisting></para>

      <para>In this section, we will modify the Thor to allow some Pipe
      Programs. In version 9.2.0 and greater, commands used in PIPE are
      restricted by default in containerized deployments unless explicitly
      allowed in the Helm chart.</para>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">thorWithPipe.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Open the default values file that you saved earlier
          (myvalues.yaml) in a text editor.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">thor:</emphasis> section
          and paste it into the new thorWithPipe.yaml file.</para>
        </listitem>

        <listitem>
          <para>Add a block at the end:</para>

          <para><programlisting>  allowedPipePrograms: 
  - sort 
  - grep 
  - echo</programlisting>This example enables three common programs. You can
          use the ones you want instead.</para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>

          <para>The resulting thorWithPipe.yaml file should look like
          this</para>

          <para><emphasis role="bold">Note:</emphasis> The comments have been
          removed to simplify the example:</para>

          <para><programlisting>thor:
- name: thor
  prefix: thor
  numWorkers: 2
  maxJobs: 4
  maxGraphs: 2
  allowedPipePrograms:
  - sort
  - grep
  - echo</programlisting></para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          thorWithPipe.yaml file file.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting># If you have previously stopped your cluster

helm install mycluster hpcc/hpcc -f thorWithPipe.yaml

# To upgrade without stopping

helm upgrade mycluster hpcc/hpcc -f thorWithPipe.yaml
</programlisting></para>
        </listitem>

        <listitem>
          <para>After you confirm that your deployment is running, submit a
          job that uses a PIPE action and specifies one of the programs you
          specified.</para>

          <para><emphasis role="bold">Note:</emphasis> If the job is too
          simple, it will execute on hThor instead of Thor and this example
          doesn't enable Pipe programs on hThor.</para>

          <para>You can create another yaml file to allow Pipe Programs on ECL
          Agent or you can use:</para>

          <para><programlisting>#OPTION('pickBestEngine',FALSE);</programlisting></para>

          <para>to force the job to run on Thor.</para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 id="CustTutorial3" role="nobrk">
      <title>Create a Custom Configuration Chart for No Thor</title>

      <para>In this section, we will create a YAML file to specify a platform
      deployment with no Thor.</para>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">nothor.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Edit the file so it disables Thor as follows:</para>

          <para><programlisting>thor: []</programlisting></para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          nothor.yaml file.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting># If you have previously stopped your cluster

helm install mycluster hpcc/hpcc -f nothor.yaml

# To upgrade without stopping

helm upgrade mycluster hpcc/hpcc -f nothor.yaml</programlisting></para>
        </listitem>

        <listitem>
          <para>After you confirm that your deployment is running, open ECL
          Watch.</para>

          <para>You should not see any Thor cluster available as a
          Target.</para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 id="CustTutorial4" role="brk">
      <title>Create a Custom Configuration Chart for No Roxie</title>

      <para>In this section, we will create a YAML file to specify a platform
      deployment with no Roxie. While the outcome is similar to what we did in
      the previous section for no Thor, the technique is different.</para>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">noroxie.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Save the default values to a text file:</para>

          <para><programlisting>helm show values hpcc/hpcc &gt; myvalues.yaml</programlisting></para>
        </listitem>

        <listitem>
          <para>Open the saved file (myvalues.yaml) in a text editor.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">roxie:</emphasis>
          section and paste it into the new noroxie.yaml file.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">eclagent:</emphasis>
          section and paste it into the new noroxie.yaml file.</para>
        </listitem>

        <listitem>
          <para>In the <emphasis role="bold">roxie</emphasis> block, edit the
          value for <emphasis role="bold">disabled:</emphasis> and change it
          to <emphasis role="bold">true</emphasis></para>

          <para>You can remove everything else from the roxie: block except
          name.</para>
        </listitem>

        <listitem>
          <para>In the <emphasis role="bold">eclagent</emphasis> block, delete
          the entire <emphasis role="bold">name: roxie-workunit</emphasis>
          block.</para>

          <para>This removes the instance of a Roxie acting as an ECL
          Agent.</para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>

          <para>The resulting noroxie.yaml file should look like this:</para>

          <para><emphasis role="bold">Note:</emphasis> The comments have been
          removed to simplify the example:</para>

          <para><programlisting>roxie:
- name: roxie
  disabled: true
  
eclagent:
- name: hthor
  replicas: 1
  maxActive: 4
  prefix: hthor
  useChildProcesses: false
  type: hthor</programlisting></para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          noroxie.yaml file.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting>helm install mycluster hpcc/hpcc -f noroxie.yaml</programlisting></para>
        </listitem>

        <listitem>
          <para>After you confirm that your deployment is running, open ECL
          Watch.</para>

          <para>You should not see any Roxie cluster available as a
          Target.</para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 id="threeiThorsOneQueue" role="nobrk">
      <title>Create a Custom Configuration Chart for Multiple Thors Listening
      to a Common Queue</title>

      <para>In this section, we will create three Thors that listen to a
      common queue (in addition to their own queue). This provides the ability
      to define distinct Thor cluster configurations but allow them to form a
      single target behind a single queue. These clusters can be bound to
      certain node pools in different availability zones, if desired. You can
      use this example as a starting point and adjust the number of Thor
      clusters you want.</para>

      <para>This is accomplished by defining additional auxiliary target
      queues for each Thor definition and using a common name as an auxiliary
      queue.</para>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">threethorsonequeue.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Open the default values file that you saved earlier
          (myvalues.yaml) in a text editor.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">thor:</emphasis> section
          and paste it into the new threethorsonequeue.yaml file.</para>
        </listitem>

        <listitem>
          <para>Copy the entire contents of the new yaml file, except the
          first line (thor:), and paste it at the end of the file <emphasis
          role="bold">twice</emphasis>.</para>

          <para>This creates three - name: sections.</para>
        </listitem>

        <listitem>
          <para>Edit the file in the following manner:</para>

          <para><orderedlist>
              <listitem>
                <para>Give each Thor a unique value for <emphasis
                role="bold">name:</emphasis>.</para>

                <para>In this example, we use <emphasis role="bold">thor1,
                thor2, </emphasis>and <emphasis
                role="bold">thor3</emphasis>.</para>
              </listitem>

              <listitem>
                <para>Add an <emphasis role="bold">auxQueues:</emphasis> entry
                to each Thor block using a common name</para>

                <para>In this example, we are using</para>

                <para><emphasis role="bold">auxQueues: [ thorQ
                ]</emphasis></para>
              </listitem>

              <listitem>
                <para>Make sure the <emphasis role="bold">prefix:</emphasis>
                is the same in each Thor block.</para>
              </listitem>
            </orderedlist></para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>

          <para>The resulting threethorsonequeue.yaml file should look like
          this:</para>

          <para><emphasis role="bold">Note:</emphasis> The comments have been
          removed to simplify the example:</para>

          <para><programlisting>thor:
- name: thor1
  auxQueues: [ thorQ ]
  maxGraphs: 2
  maxJobs: 2
  numWorkers: 4
  numWorkersPerPod: 2
  prefix: thor
- name: thor2
  maxGraphs: 2
  maxJobs: 2
  numWorkers: 4
  numWorkersPerPod: 2
  prefix: thor
  auxQueues: [ thorQ ]
- name: thor3
  maxGraphs: 2
  maxJobs: 2
  numWorkers: 4
  numWorkersPerPod: 2
  prefix: thor
  auxQueues: [ thorQ ]</programlisting></para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          threethorsonequeue.yaml file.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting># If you have previously stopped your cluster

helm install mycluster hpcc/hpcc -f threethorsonequeue.yaml

# To upgrade without stopping

helm upgrade mycluster hpcc/hpcc -f threethorsonequeue.yaml
</programlisting></para>
        </listitem>

        <listitem>
          <para>After you confirm that your deployment is running, open ECL
          Watch.</para>

          <para>You should see four Thor clusters available as Targets --
          thor1, thor2, thor3, and a fourth queue that all three Thors listen
          to-- thorQ.</para>
        </listitem>
      </orderedlist>
    </sect2>

    <sect2 id="configwithlzonly" role="nobrk">
      <title>Create a Custom Configuration Chart for a Landing Zone
      only</title>

      <para>In this section, we will create a custom configuration that
      deploys a "platform" containing only a Landing Zone. This can be useful
      if all you need is a landing zone server with dafilesrv running.</para>

      <para><emphasis role="bold">Note:</emphasis> This can only be deployed
      to a different namespace than any other platform instance.</para>

      <orderedlist>
        <listitem>
          <para>If you have not already added the HPCC Systems repository to
          the helm repository list, add it now.</para>

          <para><programlisting>helm repo add hpcc https://hpcc-systems.github.io/helm-chart/</programlisting></para>

          <para>If you have added it, update to the latest charts:</para>

          <para><programlisting>helm repo update</programlisting></para>
        </listitem>

        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">lz.yaml</emphasis> and open it in a text editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Copy and paste this code into the file:</para>

          <para><programlisting>dafilesrv:
- name: direct-access
  application: directio
  service:
    servicePort: 7100
    visibility: local
    tls: false
  resources:
    cpu: "2"
    memory: "8G"
dali: []
dfuserver: []
eclagent: []
eclccserver: []
eclscheduler: []
esp: []
roxie: []
sasha: null
thor: []
</programlisting></para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>
        </listitem>
      </orderedlist>

      <para><emphasis role="bold">Deploy using the new custom configuration
      chart.</emphasis></para>

      <orderedlist>
        <listitem>
          <para>Open a terminal and navigate to the folder where you saved the
          lz.yaml file.</para>
        </listitem>

        <listitem>
          <para>Deploy this LZ only "platform" with the the new configuration
          added to your command:</para>

          <para><programlisting>helm install mylz hpcc/hpcc -f lz.yaml
</programlisting></para>
        </listitem>

        <listitem>
          <para>Confirm it is installed using this command:</para>

          <para><programlisting>helm list </programlisting></para>
        </listitem>
      </orderedlist>
    </sect2>
  </sect1>

  <sect1 id="CostTracking1">
    <title>Container Cost Tracking</title>

    <para>With the advent of the containerized HPCC Systems platform, we have
    introduced cost tracking information. This is particularly useful when
    using cloud native HPCC Systems platform instances in a cloud setting
    where some planning and configuration can help reduce expenses.</para>

    <para>New columns have been added to the workunits and the logical files
    pages in ECL Watch. These columns can be sorted by any cost columns, just
    like the other columns in ECL Watch, by clicking at the top of the column.
    In addition, file operation costs executed by workunits are provided in
    the workunit’s metrics.</para>

    <para>As the cost tracking matures, the cost calculations also improve
    significantly providing more accurate cost tracking. For example, data
    that was accessed from page cache doesn’t incur any file access cost. HPCC
    Systems cost tracking now detects data that has been returned from the
    page cache and adjusts cost calculations appropriately resulting in more
    accurate cost calculations.</para>

    <sect2 id="TypesOfCosts">
      <title>Types of Costs</title>

      <para>There are several types of costs that are tracked.</para>

      <para><itemizedlist>
          <listitem>
            <para>Execution Cost</para>
          </listitem>

          <listitem>
            <para>Compile Cost</para>
          </listitem>

          <listitem>
            <para>File Access Cost</para>
          </listitem>

          <listitem>
            <para>File Cost at Rest</para>
          </listitem>
        </itemizedlist></para>

      <variablelist>
        <varlistentry>
          <term>NOTE:</term>

          <listitem>
            <para>While reporting accuracy has significantly improved, all
            cost values calculated and displayed remain approximate. There are
            many variables that can result in inaccuracies. These cost values
            are only intended to be used as a guide.</para>
          </listitem>
        </varlistentry>
      </variablelist>

      <sect3 id="ExecutionCost">
        <title>Execution Cost</title>

        <para>Execution Cost is the cost of executing the workunit, graph, and
        subgraphs on the Thor cluster. It includes the cost of all the nodes
        directly required to execute the job and includes the cost of:</para>

        <para><itemizedlist>
            <listitem>
              <para>Worker nodes</para>
            </listitem>

            <listitem>
              <para>Compiler nodes</para>
            </listitem>

            <listitem>
              <para>Agent nodes and the manager node</para>
            </listitem>
          </itemizedlist></para>

        <para>A workunit's execution cost value is displayed in ECL Watch on
        its summary page and is broken down at the graph, subgraph, and
        activity level. The graph and subgraph cost values are available in
        the metrics and graph viewer.</para>

        <para><variablelist>
            <varlistentry>
              <term>Note:</term>

              <listitem>
                <para>The execution cost of ROXIE workunits is not currently
                implemented.</para>
              </listitem>
            </varlistentry>
          </variablelist></para>

        <sect4 id="JobGuillotine">
          <title>Job Guillotine</title>

          <para>The risk of runaway costs is a concern for potentially
          uncapped usage-based charging. Thus the job guillotine feature is
          provided to manage this risk by setting limits on the costs using
          the <emphasis>limit</emphasis> and <emphasis>hardlimit</emphasis>
          values. When a jobs cost reaches a set amount, the job can be
          terminated and limit the costs that job may incur.</para>

          <variablelist>
            <varlistentry>
              <term>Note:</term>

              <listitem>
                <para>This feature is only supported for Thor jobs
                currently.</para>
              </listitem>
            </varlistentry>
          </variablelist>

          <graphic fileref="../../images/SCOST_img3_1.jpg"><!--ADD-IMAGE--></graphic>
        </sect4>
      </sect3>

      <sect3 id="Compile_Costs">
        <title>Compile Cost</title>

        <para>Compile costs are the costs of compiling the ECL code. The cost
        of compiling the ECL code is included as a column in the workunit
        list. In the workunit summary page there is a compile cost
        field.</para>
      </sect3>

      <sect3 id="StorageCOsts">
        <title>Storage Costs</title>

        <para>This is the cost of hosting the data in the storage plane or the
        <emphasis>File Cost At Rest</emphasis> value and the cost of
        reading/writing to the storage, is the <emphasis>File Access
        Cost</emphasis> value.</para>

        <para><variablelist>
            <varlistentry>
              <term>Note:</term>

              <listitem>
                <para>Costs are not recorded for temporary or spill files,
                because the local storage is included in the price of the VM
                used to calculate the execution costs.</para>
              </listitem>
            </varlistentry>
          </variablelist></para>

        <para>For logical files, the costs calculated are based on two types
        of file access.</para>

        <itemizedlist>
          <listitem>
            <para>File Access Cost</para>
          </listitem>

          <listitem>
            <para>File Cost at Rest</para>
          </listitem>
        </itemizedlist>

        <sect4 id="FileAccessCost">
          <title>File Access Cost</title>

          <para>File access costs are the costs of reading and writing to the
          files. Many storage planes do have a separate charge for data
          operations. The cost of reading and writing to the file is included
          in the file access cost value. Any other cost associated with file
          operations (such as delete or copy) will not be tracked or included
          as part of file access cost at this time.</para>

          <para>The costs incurred by a workunit for accessing logical files
          is also recorded in the workunit’s statistics and attributes. The
          read/write cost is recorded at the activity record and cumulated at
          the graph, the subgraph, and the workflow scope level. Cost Tracking
          detects data that has been returned from the page cache and adjusts
          cost calculations appropriately to produce more accurate cost
          calculations. These file access costs for a workunit are recorded
          with the workunit and displayed in the summary page and in the
          workunit’s metrics.</para>

          <sect5 id="FileCostAtRest">
            <title>File Cost at Rest</title>

            <para>The File Cost at Rest field is shown in the Logical File
            summary page. It is the cost of storing the file without accessing
            the data. Only the storage costs associated with housing the file
            in the cloud. This value has been added to better differentiate
            between file storage costs.</para>
          </sect5>
        </sect4>
      </sect3>
    </sect2>

    <sect2 id="CostsConfigurations">
      <title>Costs Configuration</title>

      <para>This section details setting the job costs configuration
      parameters. Job costs configuration on a cloud native HPCC Systems
      instance is done using the helm chart. By default the delivered
      <emphasis>values.yaml</emphasis> file contains a section for configuring
      costs. The costs are calculated using the default delivered values. Any
      desired changes can be done as a custom configuration similar to the
      customizations in the previous sections.</para>

      <para>For example:</para>

      <orderedlist>
        <listitem>
          <para>Create a new text file and name it <emphasis
          role="bold">mycosts.yaml</emphasis> and open it in a text
          editor.</para>

          <para>You can use any text editor.</para>
        </listitem>

        <listitem>
          <para>Save the default values to a text file:</para>

          <para><programlisting>helm show values hpcc/hpcc &gt; myvalues.yaml</programlisting></para>
        </listitem>

        <listitem>
          <para>Open the saved file (myvalues.yaml) in a text editor.</para>
        </listitem>

        <listitem>
          <para>Copy the entire <emphasis role="bold">cost:</emphasis> section
          and paste it into the new mycosts.yaml file.</para>
        </listitem>

        <listitem>
          <para>Change any desired cost related values as appropriate.</para>
        </listitem>

        <listitem>
          <para>Save the file and close the text editor.</para>
        </listitem>

        <listitem>
          <para>Deploy your HPCC Systems Platform, adding the new
          configuration to your command:</para>

          <para><programlisting>helm install mycluster hpcc/hpcc -f mycosts.yaml</programlisting></para>
        </listitem>
      </orderedlist>

      <para>The configuration values provide the pricing information and
      currency formatting information. The following cost configuration
      parameters are supported:</para>

      <para><informaltable colsep="1" frame="all" rowsep="1">
          <tgroup cols="2">
            <colspec align="left" colwidth="122.40pt"/>

            <tbody>
              <row>
                <entry><emphasis>currencyCode</emphasis></entry>

                <entry>Used for currency formatting of cost values.</entry>
              </row>

              <row>
                <entry><emphasis>perCpu</emphasis></entry>

                <entry>Cost per hour of a single cpu.</entry>
              </row>

              <row>
                <entry><emphasis>storageAtRest</emphasis></entry>

                <entry>Storage cost per gigabyte per month.</entry>
              </row>

              <row>
                <entry><emphasis>storageReads</emphasis></entry>

                <entry>Cost per 10,000 read operations.</entry>
              </row>

              <row>
                <entry><emphasis>storageWrites</emphasis></entry>

                <entry>Cost per 10,000 write operations.</entry>
              </row>
            </tbody>
          </tgroup>
        </informaltable></para>

      <sect3 id="ConfiguringCloudCosts">
        <title>Configuring Cloud Costs</title>

        <para>The default <emphasis>values.yaml</emphasis> configuration file
        is configured with the following cost parameters in the global/cost
        section:</para>

        <programlisting>  cost:
    currencyCode: USD
    perCpu: 0.126
    storageAtRest: 0.0135
    storageReads: 0.0485
    storageWrites: 0.0038
</programlisting>

        <para>The <emphasis role="bold">currencyCode</emphasis> attribute
        should be configured with the ISO 4217 country code. (HPCC Systems
        platform defaults to USD if the currency code is missing).</para>

        <para>The <emphasis role="bold">perCpu</emphasis> from the global/cost
        section applies to every component that has not been configured with
        its own perCpu value.</para>

        <para>A perCpu value specific to a component may be set by adding a
        cost/perCPU attribute under that component section.</para>

        <para>For example Dali:</para>

        <programlisting>  dali:
    - name: mydali
      <emphasis role="bold">cost:
        perCpu: </emphasis>0.24</programlisting>
      </sect3>

      <sect3 id="ThorCostsConfiguration">
        <title>Thor Cost Configurations</title>

        <para>The Thor components support additional cost parameters which are
        used for the job guillotine feature:</para>

        <para><informaltable colsep="1" frame="all" rowsep="1">
            <tgroup cols="2">
              <colspec align="left" colwidth="122.40pt"/>

              <colspec/>

              <tbody>
                <row>
                  <entry><emphasis>limit </emphasis></entry>

                  <entry>Sets the “soft” cost limit that a workunit may incur.
                  The limit is “soft” in that it may be overridden by the
                  <emphasis role="bold">maxCost</emphasis> ECL option. A node
                  will be terminated if it exceeds its <emphasis
                  role="bold">maxCost</emphasis> value (if set) or the limit
                  attribute value (if the <emphasis
                  role="bold">maxCost</emphasis> not set).</entry>
                </row>

                <row>
                  <entry><emphasis>hardlimit</emphasis></entry>

                  <entry>Sets the absolute maximum cost limit, a limit that
                  may not be overridden by setting the ECL option. The
                  <emphasis role="bold">maxCost</emphasis> value exceeding the
                  hardlimit will be ignored.</entry>
                </row>
              </tbody>
            </tgroup>
          </informaltable></para>

        <para>The following example sets the jobs cost limits, by adding the
        attributes to the Thor section of the configuration yaml.</para>

        <programlisting>thor:
- name: thor
  prefix: thor
  numWorkers: 2
  maxJobs: 4
  maxGraphs: 2
  <emphasis role="bold">cost:
    limit: 10.00   </emphasis>   # maximum cost is $10, overridable with maxCost option
    <emphasis role="bold">hardlimit: 20.00</emphasis>  # maximum cost is $20, cannot be overridden</programlisting>
      </sect3>

      <sect3 id="StorageCostParameters">
        <title>Storage Cost Parameters</title>

        <para>The storage cost parameters (<emphasis
        role="bold">storageAtRest</emphasis>, <emphasis
        role="bold">storageReads</emphasis> and <emphasis
        role="bold">storageWrites</emphasis>) may be added under the storage
        plane cost section to set cost parameters specific to the storage
        plane.</para>

        <para>For example:</para>

        <programlisting>storage:
  planes:
  - name: dali
    storageClass: ""
    storageSize: 1Gi
    prefix: "/var/lib/HPCCSystems/dalistorage"
    pvc: mycluster-hpcc-dalistorage-pvc
    category: dali
    <emphasis role="bold">cost:
      storageAtRest:</emphasis> 0.01
      <emphasis role="bold">storageReads:</emphasis> 0.001
      <emphasis role="bold">storageWrites:</emphasis> 0.04
</programlisting>

        <para>The storage cost parameters under the global section are only
        used if no cost parameters are specified on the storage plane.</para>
      </sect3>
    </sect2>
  </sect1>

  <sect1 id="S1-Cost_Optimizer">
    <title>Cost Optimizer</title>

    <para>The Cost Optimizer is a tool that analyzes Thor jobs to identify
    potential issues that could cause unnecessary costs. The optimizer is
    enabled by default and the cost optimizer analysis is generated
    automatically for all Thor jobs.</para>

    <sect2 id="Cost-OptimizerFunctionality">
      <title>Cost Optimizer Functionality</title>

      <para>The Cost Optimizer functions by examining the workunit’s graph and
      metrics to highlight issues such as skews, spills, and other suboptimal
      operations. Addressing these issues can improve performance and/or
      reduce costs.</para>

      <para>For example, the Cost Optimizer may detect among the following
      noteworthy issues:</para>

      <para><emphasis role="bold">Skews</emphasis>: Imbalanced data
      distribution causing some nodes to process more data than others.</para>

      <para><emphasis role="bold">Spills</emphasis>: Excessive data spilling
      to disk due to insufficient memory allocation.</para>

      <para><emphasis role="bold">Inefficient Joins</emphasis>: Suboptimal
      join operations leading to increased processing time.</para>

      <para>These issues result in longer execution times for the cluster,
      thereby incurring additional costs.</para>
    </sect2>

    <sect2 id="CO-CostEstimation">
      <title>Cost Estimation</title>

      <para>If your HPCC Systems deployment is configured to use the cost
      tracking settings, the Cost Optimizer provides an estimated monetary
      value for each identified issue.</para>

      <para>All identified issues are reported on the workunit’s summary page
      in ECL Watch.</para>

      <para>Review the reported issues to determine their validity and impact
      to your work and consider making changes to improve efficiency and
      reduce unnecessary costs.</para>
    </sect2>
  </sect1>

  <sect1 id="SecureLDAPaminCreds_forConatiners">
    <title>Securing Credentials</title>

    <para>Utilizing HPCC Systems in a containerized environment has some
    unique security concerns by externalizing typically internalized
    components, such as the LDAP administrators credentials.</para>

    <para>Securing the LDAP administrators credentials is accomplished by
    using either Kubernetes or Hashicorp Vault secrets. As a prerequisite you
    should be familiar with setting up Kubernetes and/or Hashicorp Vault
    secrets.</para>

    <para>The LDAP administrators account must have administrator rights to
    all of the Base DNs used by the HPCC Systems platform. In a cloud
    deployment these credentials can be exposed. A good practice then, for
    these administrator credentials is to be secured either using Kubernetes
    secrets or the Hashicorp Vault.</para>

    <sect2 id="SecuringCredentials_For_KubernetesSecrets">
      <title>Securing Credentials in Kubernetes</title>

      <para>To create a secret in Kubernetes to store the LDAP administrators
      user account credentials, use a command line interface to Kubernetes,
      and execute a command similar to the following example:</para>

      <programlisting lang="bash">kubectl create secret generic admincredssecretname --from-literal=username=hpcc_admin \
  --from-literal=password=t0pS3cr3tP@ssw0rd
</programlisting>

      <para>In the above example, the Kubernetes secret name, is
      "admincredssecretname" and it contains the LDAP administrators account
      "username" and "password" key/values. This stores the LDAP
      administrators username and password as a Kubernetes secret. Any
      additional properties are ignored.</para>

      <para>You can verify the secret you just created by executing the
      following Kubernetes command.</para>

      <programlisting lang="bash">kubectl get secret admincredssecretname</programlisting>

      <para>For more information about Kubernetes see the appropriate
      Kubernetes documentation for your implementation.</para>

      <sect3 id="Using_TheKubernetesSecret">
        <title>Using the Kubernetes Secret</title>

        <para>To deploy the Kubernetes secrets override the "secrets:" section
        in HPCC-Platform/helm/hpcc/values.yaml, or deploy with your own
        customized chart. For more information about customizing your HPCC
        Systems containerized deployment see the above sections on
        customization techniques.</para>

        <para>In your chart, create a unique key name used to reference the
        secret, and set it to the name of secret that you created in the
        previous step. In the above example it was
        "admincredssecretname".</para>

        <para>You can optionally define additional secrets as required by your
        platform security configuration. Each of these secrets would be
        created as described above and given unique names. The example below
        indicates how you can add any additional credentials or secrets to
        your Helm chart(s) if necessary.</para>

        <para>The "admincredsmountname" key/value pair already exists by
        default in the delivered HPCC Systems values.yaml file. The key is
        referenced in the component's ldap.yaml file. You may override these
        and add additional key/values as needed. The following example
        illustrates adding "additionalsecretname" and that name must match the
        name of the additional secret created using the steps above.</para>

        <programlisting lang="bash">  secrets:
     authn:
       admincredsmountname: "admincredssecretname"   #exernalize HPCC Admin creds
       additionalmountname: "additionalsecretname"   #alternate HPCC Admin creds
</programlisting>
      </sect3>

      <sect3 id="ENABLE_k8S_LDAP">
        <title>Enable LDAP Authentication</title>

        <para>In the delivered
        HPCC-Platform/esp/applications/common/ldap/ldap.yaml file, the
        "ldapAdminSecretKey" is already set to the key mount name illustrated
        in the example above. To enable LDAP authentication and to modify this
        value, you or your systems administrator can override the ESP/ECLWatch
        Helm component located in values.yaml chart as illustrated in the
        following example:</para>

        <programlisting lang="YAML">esp:
- name: eclwatch
  application: eclwatch
  auth: ldap
  ldap:
    ldapAddress: "myldapserver"
    ldapAdminSecretKey: "additionaltmountname"  # use alternate secrets creds
</programlisting>

        <para/>
      </sect3>
    </sect2>

    <sect2 id="SecuringCreds_For_HashoCorpVault">
      <title>Securing credentials in HashiCorp Vault</title>

      <para>To create and store secrets in the HashiCorp Vault, from the
      command command line interface, execute the following Vault commands.
      The secret name used in the example below is "myvaultadmincreds" and
      must be prefixed with "secret/authn/" as illustrated. The LDAP
      administrator "username" and "password" key/values are required.
      Additional properties are ignored.</para>

      <programlisting>vault kv put secret/authn/myvaultadmincreds username=hpcc_admin password=t0pS3cr3tP@ssw0rd </programlisting>

      <para>Where the "secret/authn/myvaultadmincreds" is the name of the
      secret containing the LDAP administrator username and password.</para>

      <para>To verify and confirm the secret values, execute the following
      command:</para>

      <programlisting lang="bash">vault kv get secret/authn/myvaultadmincreds</programlisting>

      <para>For more information about creating secrets for HashiCorp Vault
      see the appropriate HashiCorp documentation for your
      implementation.</para>

      <sect3 id="Deploying_HashiCorpVault">
        <title id="DeployingTheHashiCorpVault">Deploy the HashiCorp
        Vault</title>

        <para>Deploy the HashiCorp Vault secrets when you override the
        "secrets:" section in HPCC-Platform/helm/hpcc/values.yaml, or in your
        customized configuration chart. For more information about customizing
        your HPCC Systems containerized deployment see the above sections on
        customization techniques.</para>

        <para>The Vault name value is defined for this example in the
        values-secrets.yaml configuration chart. You can find an example of
        this chart in the HPCC-Platform repository under
        /helm/examples/secrets/values-secrets.yaml.</para>

        <programlisting lang="YAML">  vaults:
  authn:
    - name: my-authn-vault
      #The data node in the URL is there for use by the REST API 
      #The path inside the vault starts after /data
      url: http://${env.VAULT_SERVICE_HOST}:${env.VAULT_SERVICE_PORT}/v1/secret/data/authn/${secret}
      kind: kv-v2
</programlisting>

        <para>You could put this into your own customization chart where you
        supply your deployment with the name of the vault containing the
        credentials.</para>
      </sect3>

      <sect3 id="REF_HASHICORPVault_LDAP">
        <title>Referencing Vault Stored Authentication</title>

        <para>The key names "ldapAdminSecretKey" and "ldapAdminVaultId" are
        used by the HPCC Systems security manager to resolve the secrets, and
        must match exactly when using the Vault name set up in the previous
        steps.</para>

        <programlisting lang="YAML">esp:
- name: eclwatch
  application: eclwatch
  auth: ldap
  ldap:
    ldapAddress: "myldapserver"
    ldapAdminSecretKey: "myvaultadmincreds"
    ldapAdminVaultId: "my-authn-vault"
</programlisting>

        <para/>
      </sect3>
    </sect2>
  </sect1>
</chapter>
