# Smoketest github action
# =======================
#
# Uses cached instances of previous builds to perform partial (and therefore quicker) incremental builds.
# Once the platform is built and installed (make install),
# it runs the regression suite setup stage within the same github job ('build-and-setup').
#
# On success, an artifact is built, that contains the install binaries and
# the HPCC binaries that have accumulated from the setup stage.
#
# Once the 'build-and-setup' job is complete, the dependent regression suite jobs and unittest job are launched in parallel.
# The regression suite queries are manually sub-divided into chunks (alphabeticaly), and run via a job matrix for parallism.
# If anything fails, all jobs are aborted (fail-fast=true), and the logs are captured into a published artifact.
#
# NOTES:
# + pre-requisite build dependencies (and runtime dependencies) are listed manually, and must be kept up to date with the
#   requirements of the platform. MORE: a list of required build dependencies could be kept within the platform source and picked up
# + 'cacheversion' is purely in case it is necessary to force a cache-miss, i.e. all cached items are based on this version
# + Caching is via github's actions/cache, and is limited to 5GB total per repository, with oldest ejected first, and/or >7 days
#   cached builds are tagged with:
#    1) base+ref+SHA (exact match, e.g. hpccbuild-1-7.12.10-6c981c48ae6e35b62d86d8e59e42799c5cd14812)
#    2) base_ref (branch match, e.g. hpccbuild-1-7.12.10)
#    3) base-ref major-minor only (e.g. hpccbuild-1-7.12.)
#    4) base-ref major only (e.g. hpccbuild-1-7.)
#    5) generic cacheversion only (e.g. hpccbuild-1-)
#   The cache will initially try to match an exact key match (only true if rerunning PR and SHA same),
#   and will then failover to trying to find a match of 2-5, in that order.


name: smoketest
env:
  cacheversion: 1

on:
  pull_request:
    branches:
      - "master"
      - "candidate-*"
      - "!candidate-7.6.*"
      - "!candidate-7.4.*"
      - "!candidate-7.2.*"
      - "!candidate-7.0.*"
      - "!candidate-6.*"

# NB: this fails to cancel in-flight actions, with error 'Resource not accessible by integration',
# but it's non-fatal. Appears to be dependent on what permissions the PR owner has, i.e. the github token used
# does not have permission to cancel actions.
jobs:
  check-skip:
    # continue-on-error: true # Uncomment once integration is finished
    runs-on: ubuntu-latest
    # Map a step output to a job output
    outputs:
      should_skip: ${{ steps.skip_check.outputs.should_skip }}
    steps:
      - id: skip_check
        uses: hpcc-systems/skip-duplicate-actions@master
        with:
          github_token: ${{ github.token }}
          paths_ignore: '["clienttools/**", "devdoc/**", "dockerfiles/**", "docs/**", "helm/**" ]'

  build-and-setup:
    name: Build platform and regress setup
    needs: check-skip
    if: ${{ needs.check-skip.outputs.should_skip != 'true' }}
    runs-on: ubuntu-20.04
    timeout-minutes: 120 # Generous, typical build time from clean is < 60
    outputs:
      cache-hit: ${{ steps.cache.outputs.cache-hit }}

    steps:
    - name: vars
      id: vars
      run: |
        if [[ "${{ github.event_name }}" = 'pull_request' ]]; then \
          echo ::set-output name=branch::${{ github.head_ref }}; \
          echo ::set-output name=sha::${{ github.event.pull_request.head.sha }}; \
          echo ::set-output name=base_ref::${{ github.base_ref }}; \
          versioned=$(echo ${{ github.base_ref }} | sed -E -n 's/^(.*)-([0-9]+)\.([0-9]+)\.([0-9]+|x)(-[0-9]+|).*$/\1 \2 \3 \4 \5/p'); \
          if [[ "${versioned}" ]]; then \
            echo matched version = ${versioned}; \
            IFS=' ' read prefix major minor point cand <<< ${versioned}; \
            echo "name=base-majorminor-restore-key::hpccbuild-${{ env.cacheversion }}-${prefix}-${major}.${minor}." ;\
            echo "name=base-majoronly-restore-key::hpccbuild-${{ env.cacheversion }}-${prefix}-${major}." ;\
            echo ::set-output name=base-majorminor-restore-key::hpccbuild-${{ env.cacheversion }}-${prefix}-${major}.${minor}. ;\
            echo ::set-output name=base-majoronly-restore-key::hpccbuild-${{ env.cacheversion }}-${prefix}-${major}. ;\
          fi; \
        else \
          echo ::set-output name=branch::${GITHUB_REF#refs/heads/}; \
          echo ::set-output name=sha::${{ github.sha }}; \
          echo ::set-output name=base_ref::${GITHUB_REF#refs/heads/}; \
        fi
        if [[ "${{ github.event.pull_request.head.repo.owner.login }}" = "${{ github.repository_owner }}" ]]; then \
          echo ::set-output name=repository::${{ github.repository }}; \
        else \
          echo ::set-output name=repository::$(echo -n ${{ github.event.pull_request.head.repo.owner.login }}/ ; echo -n ${{ github.repository }} | sed -E -n 's@^[^/]+/(.+)$@\1@p'); \
        fi

    # NB: restore-keys set to e.g. hpccbuild-1-7.12.10, hpccbuild-1-7.12, hpccbuild-1-7, hpccbuild-1-
    - name: Fetch cache
      id: cache
      uses: actions/cache@v2
      with:
        path: |
          build-cache
          src-cache
        key: hpccbuild-${{ env.cacheversion }}-${{ steps.vars.outputs.base_ref }}-${{ steps.vars.outputs.sha }}
        restore-keys: |
          hpccbuild-${{ env.cacheversion }}-${{ steps.vars.outputs.base_ref }}
          ${{ steps.vars.outputs.base-majorminor-restore-key }}
          ${{ steps.vars.outputs.base-majoronly-restore-key }}
          hpccbuild-${{ env.cacheversion }}-

    - name: tracing
      run: |
        echo "Branch     = ${{ steps.vars.outputs.branch }}"
        echo "Base ref   = ${{ steps.vars.outputs.base_ref }}"
        echo "SHA        = ${{ steps.vars.outputs.sha}}"
        echo "Action     = ${{ github.action }}"
        echo "Event      = ${{ github.event_name }}"
        echo "Actor      = ${{ github.actor }}"
        echo "github.repository = ${{ github.repository }}"
        echo "repository = ${{ steps.vars.outputs.repository }}"
        echo "repository_owner = ${{ github.repository_owner }}"
        echo "github.workspace = ${{ github.workspace }}"
        echo "runner.workspace = ${{ runner.workspace }}"
        echo "github.event.pull_request.head.repo.owner.login = ${{ github.event.pull_request.head.repo.owner.login }}"

        if [[ "${{ github.event_name }}" = 'pull_request' ]]; then \
          echo "PR base_ref = ${{ github.base_ref }}"; \
          echo "PR head_ref = ${{ github.head_ref }}"; \
          echo "PR base SHA = ${{ github.event.pull_request.base.sha }}"; \
        fi
        echo restore-key1: hpccbuild-${{ env.cacheversion }}-${{ steps.vars.outputs.base_ref }}
        echo restore-key2: ${{ steps.vars.outputs.base-majorminor-restore-key }}
        echo restore-key3: ${{ steps.vars.outputs.base-majoronly-restore-key }}
        echo restore-key4: hpccbuild-${{ env.cacheversion }}-

    # NB: actions/cache does not set cache-hit to true if restore-keys used.
    # So here we check if a cache was restored, and set a separate variable 'cache-exists' if it does.
    - name: Check cache
      if: steps.cache.outputs.cache-hit != 'true'
      id: check-cache
      run: |
        if [[ -n "${{ secrets.SMOKETEST_SKIP_CACHE }}" ]]; then \
          echo "Cache found, but ignored because SMOKETEST_SKIP_CACHE set" ;\
          rm -rf build-cache src-cache; \
        else
          echo ::set-output name=cache-exists::$(if [[ -d build-cache ]]; then echo true; else echo false; fi) ;\
          if [[ -d build-cache ]]; then \
            stat build-cache src-cache; \
            du -sh build-cache src-cache; \
          fi ;\
        fi

    - name: Dependencies20.04
      if: steps.cache.outputs.cache-hit != 'true'
      run: |
        sudo apt-get update
        sudo apt-get -yq install bison flex build-essential binutils-dev libldap2-dev libcppunit-dev libicu-dev libxslt1-dev \
          zlib1g-dev libboost-regex-dev libarchive-dev libv8-dev default-jdk libapr1-dev libaprutil1-dev libiberty-dev \
          libhiredis-dev libtbb-dev libxalan-c-dev libnuma-dev nodejs libevent-dev libatlas-base-dev libblas-dev python3-dev \
          default-libmysqlclient-dev libsqlite3-dev libmemcached-dev libcurl4-openssl-dev pkg-config libtool autotools-dev automake \
          libssl-dev xmlstarlet

    # See: https://discourse.cmake.org/t/error-when-installing-targets-and-exports-in-3-19-1/2245/6
    - name: cmake-3.19.1-workaround
      run: |
        mkdir cmake
        cd cmake
        cmake_version=$(cmake --version | head -n1 | awk '{ print $3 }')
        if [[ ${cmake_version} == '3.19.1' ]]; then \
          echo "cmake 3.19.1 causes aws build failure, fetching and installing cmake 3.18.5"
          wget https://github.com/Kitware/CMake/releases/download/v3.18.5/cmake-3.18.5-Linux-x86_64.tar.gz; \
          tar xpfz cmake-3.18.5-Linux-x86_64.tar.gz; \
          ln -s  cmake-3.18.5-Linux-x86_64/bin/cmake ./cmake; \
        else \
          ln -s `which cmake` ./cmake; \
        fi

    # On a cache hit (NB: whether exact via key or via a restore-key),
    # if SHA of cache can be found:
    # 1) mv cache into place (build-cache->build)
    # 2) fetch repo branch
    # 3) checkout source @ SHA
    #    - if it fails (because SHA can't be found), checkout base_ref
    # 4) get submodules
    # 5) copy src-cache files into place
    # 6) touch all files so that 'old' [before original make timestamp], i.e. so behind objects in cache
    # 7) checkout pr branch - ensuring only pr files that differ are updated (and hence will rebuild)
    # 8) list updated files (for tracing only)
    - name: Cache hit prep
      if: steps.cache.outputs.cache-hit != 'true' && steps.check-cache.outputs.cache-exists == 'true'
      run: |
        echo Attempting to use existing cache
        echo Fetching branch: ${{ steps.vars.outputs.branch }}
        git clone --branch ${{ steps.vars.outputs.branch }} -n https://github.com/${{ steps.vars.outputs.repository }} src
        cd src
        if [[ "commit" == "$(git cat-file -t $(cat ../build-cache/cache-sha))" ]]; then \
          mv ../build-cache ../build ; \
          echo Checking out cache SHA: $(cat ../build/cache-sha); \
          git checkout $(cat ../build/cache-sha); \
          git submodule update --init --recursive --jobs 4 ; \
          cd ../src-cache; \
          echo "Cached source tree files:" ; \
          find . -type f; \
          echo ================ ; \
          find . -type f | cpio -p -dum ../src ; \
          cd ../src; \
          find . -type f -exec touch -r ../build/cache-timestamp {} + ; \
          git checkout ${{ steps.vars.outputs.branch }} ;\
          git submodule update --init --recursive --jobs 4 ; \
          echo Changed files \(from SHA: $(cat ../build/cache-sha)\): ; \
          find -name '.git*' -prune -o -newer ../build/cache-timestamp -type f -print ; \
        else \
          echo git diff failed \(SHA $(cat ../build-cache/cache-sha) missing?\). Using base_ref; \
          rm -rf ../build-cache ../src-cache ; \
          mkdir ../build ; \
          mkdir ../src-cache ; \
          git checkout ${{ steps.vars.outputs.branch }} ; \
          git submodule update --init --recursive --jobs 4 ; \
        fi
    - name: Cache miss checkout
      if: steps.cache.outputs.cache-hit != 'true' && steps.check-cache.outputs.cache-exists != 'true'
      uses: actions/checkout@v2
      with:
        submodules: recursive
        path: src

    - name: Cache miss prep
      if: steps.cache.outputs.cache-hit != 'true' && steps.check-cache.outputs.cache-exists != 'true'
      run: |
        rm -rf build src-cache
        mkdir build
        mkdir src-cache

    # Subsequent cache hit builds use cache-timestamp to ensure all sources are marked 'old',
    # except those changed between the cache SHA and the SHA being built.
    # NB: BUILD_TAG is overridden to a constant "smoketest", this is to prevent the auto-generated build tag being
    # used, which would cause it to change per PR (per SHA), and because it's in a common header, cause a lot of undesirable rebuilding.
    - name: Build
      if: steps.cache.outputs.cache-hit != 'true'
      run: |
        cd build
        if [[ ! -f cache-timestamp ]]; then touch cache-timestamp; fi
        touch ../cmake-timestamp
        ../cmake/cmake ../src -Wno-dev -DRUNTIME_USER=$(whoami) -DRUNTIME_GROUP=$(id -gn) -DDESTDIR=$(realpath ..)/install -DINCLUDE_PLUGINS=1 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DUSE_PYTHON2=0 -DUSE_PYTHON3=1 -DSUPPRESS_SPARK=1 -DUSE_CPPUNIT=1 -DUSE_CASSANDRA=Off -DCMAKE_CXX_FLAGS="-DBUILD_TAG=\\\"dummytag\\\" -DBUILD_VERSION_MAJOR=1 -DBUILD_VERSION_MINOR=1 -DBUILD_VERSION_POINT=0" -DBUILD_TAG="smoketest"
        make -j$(nproc) install

    - name: build-logs-artifact
      if: ${{ failure() }}
      uses: actions/upload-artifact@v2
      with:
        name: build-logs
        path: |
          build/CMakeCache.txt
          build/CMakeFiles/CMakeOutput.log
          build/CMakeFiles/CMakeError.log

    # Cache contains:
    # - make binaries (build-cache)
    # - Any sources written since cache-timestamp within the source dir (src-cache) (e.g. AWS writes a config header)
    # - cache-timestamp, timestamp of cache-miss build. All files except diffs set to this time, ensuring no existing binaries are rebuilt
    # - cache-sha, the SHA of the commit built. On a cache-hit, used to find changed files and ensure they are only ones rebuilt.
    - name: Prepare cache
      if: steps.cache.outputs.cache-hit != 'true'
      run: |
        echo ${{ steps.vars.outputs.sha }} > build/cache-sha
        mv build build-cache
        cd src
        find -name '.git*' -prune -o -newer ../cmake-timestamp -type f -print | cpio -p -dum ../src-cache

    # - alter stock ecl-test.json, to point to install dir (using jq)
    # - create a clean copy of the install directory (for later reuse)
    # - rm hpcc-data from copy (the post-setup hpcc-data will be moved in when done)
    - name: Prepare install artifact
      if: steps.cache.outputs.cache-hit != 'true' && github.event_name == 'pull_request'
      run: |
        # configure ecl-test.json with correct paths
        jq --arg rootdir "${{ github.workspace }}" \
          '.Regress.dropzonePath = $rootdir + "/install" + .Regress.dropzonePath | .Regress.setupExtraParams.OriginalTextFilesOsPath = $rootdir + "/install" + .Regress.setupExtraParams.OriginalTextFilesOsPath | .Regress.setupExtraDParams.HPCCBaseDir = $rootdir + "/install" + .Regress.setupExtraDParams.HPCCBaseDir | .Regress.regressionDir = $rootdir + "/regress" | .Regress.maxAttemptCount = "1" | .Regress.logDir = $rootdir + "/regress/log"' \
          install/opt/HPCCSystems/testing/regress/ecl-test.json > ecl-test.json
        mv -f ecl-test.json install/opt/HPCCSystems/testing/regress/ecl-test.json
        # configure environment.xml to slavesPerNode=2, channelsPerNode=1
        xmlstarlet ed -L -u 'Environment/Software/ThorCluster/@slavesPerNode' -v 2 -u 'Environment/Software/ThorCluster/@channelsPerSlave' -v 1 install/etc/HPCCSystems/environment.xml
        cp ${{ github.workspace }}/src/.github/workflows/timeoutcmd install/opt/HPCCSystems/bin/
        mkdir copy
        cp -rp install copy/
        rm -rf copy/install/var/lib/HPCCSystems/hpcc-data
        rm -rf copy/install/var/lib/HPCCSystems/queries

    - name: Run regression suite setup
      if: steps.cache.outputs.cache-hit != 'true' && github.event_name == 'pull_request'
      timeout-minutes: 10
      run: |
        export LANG="en_US.UTF-8"
        sudo update-locale
        source install/opt/HPCCSystems/sbin/hpcc_setenv
        install/opt/HPCCSystems/etc/init.d/hpcc-init start
        mkdir -p regress
        cd install/opt/HPCCSystems/testing/regress
        # force regression suite to timeout after 8 minutes, so it captures ZAP report of any inflight hung queries
        timeoutcmd $((8 * 60)) \
          ./ecl-test setup --pq 2 --generateStackTrace
        ${{ github.workspace }}/install/opt/HPCCSystems/etc/init.d/hpcc-init stop

    - name: regression-setup-logs-artifact
      if: ${{ failure() || cancelled() }}
      uses: actions/upload-artifact@v2
      with:
        name: regress-setup-logs
        path: |
          install/var/log/HPCCSystems
          regress/

    # - mv regression suite setup created data from hpcc-data and queries into copy of install
    # - create tarball of install for artifact uploading
    - name: Finalize install artifact
      if: steps.cache.outputs.cache-hit != 'true' && github.event_name == 'pull_request'
      run: |
        mv install/var/lib/HPCCSystems/hpcc-data copy/install/var/lib/HPCCSystems/
        mv install/var/lib/HPCCSystems/queries copy/install/var/lib/HPCCSystems/
        cd copy
        tar --zstd -cf ../install.tgz install

    - name: Upload install artifact
      if: steps.cache.outputs.cache-hit != 'true' && github.event_name == 'pull_request'
      uses: actions/upload-artifact@v2
      with:
        name: installsetup-artifact
        path: |
          install.tgz

  # Matrix of jobs run in parallel once build+setup above completes successfully.
  # All use the post-setup install.tgz artifact, that contains binaries and setup state
  # Break each engine run into sets for speed
  # NB: each regression suite job, runs these steps:
  # - installs dependencies (probably too many for runtime)
  # - Starts HPCC
  # - Runs regression suite with params { engine, match[pattern,exclude] }
  # TODO: needs to process results, capture report, to be assembled by workflow when all jobs done
  regression-jobs:
    needs: build-and-setup
    if: needs.build-and-setup.outputs.cache-hit != 'true' && github.event_name == 'pull_request'
    timeout-minutes: 30
    runs-on: ubuntu-20.04
    strategy:
      fail-fast: true
      matrix:
        engine: ['hthor', 'thor', 'roxie']
        match:
        - pattern: '[a-d]*.ecl'
        - pattern: '[e-h]*.ecl'
        - pattern: '[i-l]*.ecl'
        - pattern: '[m-q]*.ecl'
        - pattern: '[r-u]*.ecl'
          exclude: teststdlibrary.ecl
        - pattern: '[v-z]*.ecl'
        include:
        - engine: 'hthor'
          match:
            pattern: teststdlibrary.ecl
        - engine: 'thor'
          match:
            pattern: teststdlibrary.ecl
        - engine: 'roxie'
          match:
            pattern: teststdlibrary.ecl

    steps:
    - uses: actions/download-artifact@v2
      with:
        name: installsetup-artifact

    - name: vars
      id: vars
      run: |
        echo ::set-output name=matrix-setname::$(echo -n ${{ matrix.match.pattern }} | tr -c "[:alnum:]" _)

    - name: Prerequisites
      run: |
        sudo apt-get update
        sudo apt-get -yq install bison flex build-essential binutils-dev libldap2-dev libcppunit-dev libicu-dev libxslt1-dev \
          zlib1g-dev libboost-regex-dev libarchive-dev libv8-dev default-jdk libapr1-dev libaprutil1-dev libiberty-dev \
          libhiredis-dev libtbb-dev libxalan-c-dev libnuma-dev nodejs libevent-dev libatlas-base-dev libblas-dev python3-dev \
          default-libmysqlclient-dev libsqlite3-dev libmemcached-dev libcurl4-openssl-dev pkg-config libtool autotools-dev automake \
          libssl-dev

    - name: run
      run: |
        export LANG="en_US.UTF-8"
        sudo update-locale
        tar --zstd -xf install.tgz
        source install/opt/HPCCSystems/sbin/hpcc_setenv
        install/opt/HPCCSystems/etc/init.d/hpcc-init start
        cd install/opt/HPCCSystems/testing/regress

        (cd ecl; ls ${{ matrix.match.pattern }}) > matches.tmp
        echo queries are:
        cat matches.tmp
        if [[ -z "${{ matrix.match.exclude }}" ]]; then \
          queries="$(cat matches.tmp | tr '\n' ' ')"; \
        else \
          queries="$(cd ecl; ls ${{ matrix.match.exclude }} | grep -v -f - ../matches.tmp | tr '\n' ' ')"; \
        fi
        echo queries after exclude: ${queries}

        # force regression suite to timeout after 28 minutes, so it captures ZAP report of any inflight hung queries
        timeoutcmd $((28 * 60)) \
          ./ecl-test query --pq 2 --target ${{ matrix.engine }} --excludeclass python2,embedded-r,embedded-js,3rdpartyservice,spray --generateStackTrace ${queries}
        grep Failure: ${{ github.workspace }}/regress/log/${{ matrix.engine }}.*.log
        if [[ "$(grep -oP '(?<=^Failure: )[0-9]+$' ${{ github.workspace }}/regress/log/${{ matrix.engine }}.*.log)" -gt 0 ]]; then exit 1; fi

    - name: regression-run-logs-artifact
      if: ${{ failure() || cancelled() }}
      uses: actions/upload-artifact@v2
      with:
        name: regression-run-logs-${{ matrix.engine }}-${{ steps.vars.outputs.matrix-setname }}
        path: |
          install/var/log/HPCCSystems
          regress/
        if-no-files-found: error


  # NB: this doesn't really need the post-setup data files included in install.tgz
  # but as this is relatively quick and in parallel with others, it probably doesn't matter
  unittests:
    needs: build-and-setup
    if: needs.build-and-setup.outputs.cache-hit != 'true' && github.event_name == 'pull_request'
    timeout-minutes: 10
    runs-on: ubuntu-20.04
    steps:
    - uses: actions/download-artifact@v2
      with:
        name: installsetup-artifact

    - name: Prerequisites
      run: |
        sudo apt-get update
        sudo apt-get -yq install bison flex build-essential binutils-dev libldap2-dev libcppunit-dev libicu-dev libxslt1-dev \
          zlib1g-dev libboost-regex-dev libarchive-dev libv8-dev default-jdk libapr1-dev libaprutil1-dev libiberty-dev \
          libhiredis-dev libtbb-dev libxalan-c-dev libnuma-dev nodejs libevent-dev libatlas-base-dev libblas-dev python3-dev \
          default-libmysqlclient-dev libsqlite3-dev libmemcached-dev libcurl4-openssl-dev pkg-config libtool autotools-dev automake \
          libssl-dev

    - name: run
      run: |
        export LANG="en_US.UTF-8"
        sudo update-locale
        tar --zstd -xf install.tgz
        install/opt/HPCCSystems/bin/unittests
